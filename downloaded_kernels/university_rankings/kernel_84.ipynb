{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bd0ce88a-c72e-4074-8fa9-2d811c88d066"
      },
      "source": [
        "### In this analysis, I check for bias shown towards/against universities based on the country of the university."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a6042b82-8ac0-d200-1ec5-bab808b81057"
      },
      "source": [
        "### Part 1 - Cleaning Data\n",
        "\n",
        "The data from 3 ranking systems needs to be cleaned and we need to standardize the names of Universities for all ranking systems based on which can merge data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5c56de16-13dd-8d3e-6824-d4ba66c722bb"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "import IPython\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "matplotlib.style.use('ggplot')\n",
        "%matplotlib inline\n",
        "import re\n",
        "import math\n",
        "from scipy import stats\n",
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans\n",
        "import sklearn.metrics as sm\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "# Setting options\n",
        "pd.set_option('display.max_rows', 5000)\n",
        "pd.set_option('display.max_columns', 5000)\n",
        "pd.set_option('display.width', 5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7b097a56-08cc-74d3-7185-1955dbaac52a"
      },
      "outputs": [],
      "source": [
        "# Loading data \n",
        "times_df = pd.read_csv('../input/timesData.csv')\n",
        "cwur_df = pd.read_csv('../input/cwurData.csv')\n",
        "shanghai_df = pd.read_csv('../input/shanghaiData.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "db183b58-8ded-c910-b26f-aaac02b19ce2"
      },
      "outputs": [],
      "source": [
        "# Cleaning data\n",
        "\n",
        "times_df = times_df.replace(\"\u00c9cole Normale Sup\u00e9rieure\", \"Ecole Normale Superieure\")\n",
        "times_df = times_df.replace(\"\u00c9cole Polytechnique\", \"Ecole Polytechnique\")\n",
        "times_df = times_df.replace(\"\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne\",\"Ecole Polytechnique Federale de Lausanne\")\n",
        "times_df = times_df.replace(\"ETH Zurich \u2013 Swiss Federal Institute of Technology Zurich\",\n",
        "                            \"Swiss Federal Institute of Technology Zurich\")\n",
        "times_df = times_df.replace(\"King\u2019s College London\", \"King's College London\")\n",
        "times_df = times_df.replace(\"Rutgers, the State University of New Jersey\", \"Rutgers University, New Brunswick\")\n",
        "times_df = times_df.replace(\"The University of Queensland\", \"University of Queensland\")\n",
        "times_df = times_df.replace(\"University of G\u00f6ttingen\", \"University of Gottingen\")\n",
        "times_df = times_df.replace(\"University of Michigan\", \"University of Michigan, Ann Arbor\")\n",
        "times_df = times_df.replace(\"University of Minnesota\", \"University of Minnesota, Twin Cities\")\n",
        "times_df = times_df.replace(\"Paris-Sud University\", \"University of Paris-Sud\")\n",
        "times_df = times_df.replace(\"Washington University in St Louis\", \"Washington University in St. Louis\")\n",
        "times_df = times_df.replace(\"University of Massachusetts\", \"University of Massachusetts, Amherst\")\n",
        "times_df = times_df.replace(\"Wageningen University and Research Center\", \"Wageningen University and Research Centre\")\n",
        "times_df = times_df.replace(\"Indiana University\", \"Indiana University Bloomington\")\n",
        "times_df = times_df.replace(\"Paris Diderot University \u2013 Paris 7\", \"Paris Diderot University\")\n",
        "times_df = times_df.replace(\"KTH Royal Institute of Technology\", \"Royal Institute of Technology\")\n",
        "times_df = times_df.replace(\"Universit\u00e9 Libre de Bruxelles\", \"University Libre Bruxelles\")\n",
        "times_df = times_df.replace(\"University of S\u00e3o Paulo\", \"University of Sao Paulo\")\n",
        "times_df = times_df.replace(\"Universit\u00e9 Catholique de Louvain\", \"Catholic University of Louvain\")\n",
        "times_df = times_df.replace(\"Aix-Marseille University\", \"Aix Marseille University\")\n",
        "\n",
        "cwur_df = cwur_df.replace(\"University of G\u00f6ttingen\", \"University of Gottingen\")\n",
        "cwur_df = cwur_df.replace(\"\u00c9cole normale sup\u00e9rieure - Paris\", \"Ecole Normale Superieure\")\n",
        "cwur_df = cwur_df.replace(\"\u00c9cole Polytechnique\", \"Ecole Polytechnique\")\n",
        "cwur_df = cwur_df.replace(\"Indiana University - Bloomington\", \"Indiana University Bloomington\")\n",
        "cwur_df = cwur_df.replace(\"Ludwig Maximilian University of Munich\", \"LMU Munich\")\n",
        "cwur_df = cwur_df.replace(\"Ohio State University, Columbus\", \"Ohio State University\")\n",
        "cwur_df = cwur_df.replace(\"Paris Diderot University - Paris 7\", \"Paris Diderot University\")\n",
        "cwur_df = cwur_df.replace(\"Pennsylvania State University, University Park\", \"Pennsylvania State University\")\n",
        "cwur_df = cwur_df.replace(\"Pierre-and-Marie-Curie University\", \"Pierre and Marie Curie University\")\n",
        "cwur_df = cwur_df.replace(\"Purdue University, West Lafayette\", \"Purdue University\")\n",
        "cwur_df = cwur_df.replace(\"Rutgers University-New Brunswick\", \"Rutgers University, New Brunswick\")\n",
        "cwur_df = cwur_df.replace(\"Swiss Federal Institute of Technology in Zurich\", \"Swiss Federal Institute of Technology Zurich\")\n",
        "cwur_df = cwur_df.replace(\"Swiss Federal Institute of Technology in Lausanne\",\"Ecole Polytechnique Federale de Lausanne\")\n",
        "cwur_df = cwur_df.replace(\"Technion \\xe2\\x80\\x93 Israel Institute of Technology\", \"Technion-Israel Institute of Technology\")\n",
        "cwur_df = cwur_df.replace(\"Texas A&M University, College Station\", \"Texas A&M University\")\n",
        "cwur_df = cwur_df.replace(\"University of Illinois at Urbana\u2013Champaign\", \"University of Illinois at Urbana-Champaign\")\n",
        "cwur_df = cwur_df.replace(\"University of Pittsburgh - Pittsburgh Campus\", \"University of Pittsburgh\")\n",
        "cwur_df = cwur_df.replace(\"University of Washington - Seattle\", \"University of Washington\")\n",
        "cwur_df = cwur_df.replace(\"University of Wisconsin\u2013Madison\", \"University of Wisconsin-Madison\")\n",
        "cwur_df = cwur_df.replace(\"Katholieke Universiteit Leuven\", \"KU Leuven\")\n",
        "cwur_df = cwur_df.replace(\"Ruprecht Karl University of Heidelberg\", \"Heidelberg University\")\n",
        "cwur_df = cwur_df.replace(\"London School of Economics\", \"London School of Economics and Political Science\")\n",
        "cwur_df = cwur_df.replace(\"University of Massachusetts Amherst\", \"University of Massachusetts, Amherst\")\n",
        "cwur_df = cwur_df.replace(\"Technion \u2013 Israel Institute of Technology\", \"Technion Israel Institute of Technology\")\n",
        "cwur_df = cwur_df.replace(\"University of Colorado Denver\", \"University of Colorado at Denver\")\n",
        "cwur_df = cwur_df.replace(\"Albert Ludwig University of Freiburg\", \"University of Freiburg\")\n",
        "cwur_df = cwur_df.replace(\"Universit\u00e9 libre de Bruxelles\", \"University Libre Bruxelles\")\n",
        "cwur_df = cwur_df.replace(\"University of S\u00e3o Paulo\", \"University of Sao Paulo\")\n",
        "cwur_df = cwur_df.replace(\"Aix-Marseille University\", \"Aix Marseille University\")\n",
        "cwur_df = cwur_df.replace(\"Universit\u00e9 catholique de Louvain\", \"Catholic University of Louvain\")\n",
        "cwur_df = cwur_df.replace(\"Trinity College, Dublin\", \"Trinity College Dublin\")\n",
        "\n",
        "shanghai_df = shanghai_df.replace(\"Arizona State University - Tempe\", \"Arizona State University\")\n",
        "shanghai_df = shanghai_df.replace(\"Ecole Normale Superieure - Paris\", \"Ecole Normale Superieure\")\n",
        "shanghai_df = shanghai_df.replace(\"Massachusetts Institute of Technology (MIT)\", \"Massachusetts Institute of Technology\")\n",
        "shanghai_df = shanghai_df.replace(\"Pennsylvania State University - University Park\", \"Pennsylvania State University\")\n",
        "shanghai_df = shanghai_df.replace(\"Pierre and Marie  Curie University - Paris 6\", \"Pierre and Marie Curie University\")\n",
        "shanghai_df = shanghai_df.replace(\"Purdue University - West Lafayette\", \"Purdue University\")\n",
        "shanghai_df = shanghai_df.replace(\"Rutgers, The State University of New Jersey - New Brunswick\",\n",
        "                                  \"Rutgers University, New Brunswick\")\n",
        "shanghai_df = shanghai_df.replace(\"Technical University Munich\", \"Technical University of Munich\")\n",
        "shanghai_df = shanghai_df.replace(\"Texas A & M University\", \"Texas A&M University\")\n",
        "shanghai_df = shanghai_df.replace(\"Texas A&M University - College Station\", \"Texas A&M University\")\n",
        "shanghai_df = shanghai_df.replace(\"The Australian National University\", \"Australian National University\")\n",
        "shanghai_df = shanghai_df.replace(\"The Hebrew University of Jerusalem\", \"Hebrew University of Jerusalem\")\n",
        "shanghai_df = shanghai_df.replace(\"The Imperial College of Science, Technology and Medicine\", \"Imperial College London\")\n",
        "shanghai_df = shanghai_df.replace(\"The Johns Hopkins University\", \"Johns Hopkins University\")                                \n",
        "shanghai_df = shanghai_df.replace(\"The Ohio State University - Columbus\",\"Ohio State University\")\n",
        "shanghai_df = shanghai_df.replace(\"The University of Edinburgh\",\"University of Edinburgh\")\n",
        "shanghai_df = shanghai_df.replace(\"The University of Manchester\", \"University of Manchester\")\n",
        "shanghai_df = shanghai_df.replace(\"The University of Melbourne\",\"University of Melbourne\")\n",
        "shanghai_df = shanghai_df.replace(\"The University of Queensland\", \"University of Queensland\")\n",
        "shanghai_df = shanghai_df.replace(\"The University of Texas at Austin\", \"University of Texas at Austin\")\n",
        "shanghai_df = shanghai_df.replace(\"The University of Texas Southwestern Medical Center at Dallas\",\n",
        "                                  \"University of Texas Southwestern Medical Center\")\n",
        "shanghai_df = shanghai_df.replace(\"The University of Tokyo\",\"University of Tokyo\")\n",
        "shanghai_df = shanghai_df.replace(\"The University of Western Australia\", \"University of Western Australia\")\n",
        "shanghai_df = shanghai_df.replace(\"University of California-Berkeley\", \"University of California, Berkeley\")\n",
        "shanghai_df = shanghai_df.replace(\"University of Colorado at Boulder\", \"University of Colorado Boulder\")\n",
        "shanghai_df = shanghai_df.replace(\"University of Michigan - Ann Arbor\", \"University of Michigan, Ann Arbor\")\n",
        "shanghai_df = shanghai_df.replace(\"University of Michigan-Ann Arbor\", \"University of Michigan, Ann Arbor\")\n",
        "shanghai_df = shanghai_df.replace(\"University of Paris Sud (Paris 11)\", \"University of Paris-Sud\")\n",
        "shanghai_df = shanghai_df.replace(\"University of Paris-Sud (Paris 11)\", \"University of Paris-Sud\")\n",
        "shanghai_df = shanghai_df.replace(\"University of Pittsburgh-Pittsburgh Campus\", \"University of Pittsburgh\")\n",
        "shanghai_df = shanghai_df.replace(\"University of Pittsburgh, Pittsburgh Campus\", \"University of Pittsburgh\")\n",
        "shanghai_df = shanghai_df.replace(\"University of Wisconsin - Madison\", \"University of Wisconsin-Madison\")\n",
        "shanghai_df = shanghai_df.replace(\"University of Munich\",\"LMU Munich\")\n",
        "shanghai_df = shanghai_df.replace(\"Moscow State University\", \"Lomonosov Moscow State University\")\n",
        "shanghai_df = shanghai_df.replace(\"University of Massachusetts Medical School - Worcester\",\n",
        "                                  \"University of Massachusetts Medical School\")\n",
        "shanghai_df = shanghai_df.replace(\"Joseph Fourier University (Grenoble 1)\", \"Joseph Fourier University\")\n",
        "shanghai_df = shanghai_df.replace(\"University Paris Diderot - Paris 7\", \"Paris Diderot University\")\n",
        "shanghai_df = shanghai_df.replace(\"University of Wageningen\", \"Wageningen University and Research Centre\")\n",
        "shanghai_df = shanghai_df.replace(\"The University of Texas M. D. Anderson Cancer Center\",\n",
        "                                  \"University of Texas MD Anderson Cancer Center\")\n",
        "shanghai_df = shanghai_df.replace(\"Technion-Israel Institute of Technology\", \"Technion Israel Institute of Technology\")\n",
        "shanghai_df = shanghai_df.replace(\"Swiss Federal Institute of Technology Lausanne\", \"Ecole Polytechnique Federale de Lausanne\")\n",
        "shanghai_df = shanghai_df.replace(\"University of Frankfurt\", \"Goethe University Frankfurt\")\n",
        "shanghai_df = shanghai_df.replace(\"The University of Glasgow\", \"University of Glasgow\")\n",
        "shanghai_df = shanghai_df.replace(\"The University of Sheffield\", \"University of Sheffield\")\n",
        "shanghai_df = shanghai_df.replace(\"The University of New South Wales\", \"University of New South Wales\")\n",
        "shanghai_df = shanghai_df.replace(\"University of Massachusetts Amherst\", \"University of Massachusetts, Amherst\")\n",
        "shanghai_df = shanghai_df.replace(\"University of Goettingen\", \"University of Gottingen\")\n",
        "shanghai_df = shanghai_df.replace(\"The University of Texas at Dallas\", \"University of Texas at Dallas\")\n",
        "shanghai_df = shanghai_df.replace(\"The University of Hong Kong\", \"University of Hong Kong\")\n",
        "shanghai_df = shanghai_df.replace(\"The Hong Kong University of Science and Technology\",\n",
        "                                  \"Hong Kong University of Science and Technology\")\n",
        "shanghai_df = shanghai_df.replace(\"Royal Holloway, U. of London\", \"Royal Holloway, University of London\")\n",
        "shanghai_df = shanghai_df.replace(\"Queen Mary, University of London\", \"Queen Mary University of London\")\n",
        "shanghai_df = shanghai_df.replace(\"Korea Advanced Institute of Science and Technology\",\n",
        "                                  \"Korea Advanced Institute of Science and Technology (KAIST)\")\n",
        "\n",
        "# recast data type\n",
        "times_df['international'] = times_df['international'].replace('-', np.nan)\n",
        "times_df['international'] = times_df['international'].astype(float)\n",
        "times_df['income'] = times_df['income'].replace('-', np.nan)\n",
        "times_df['income'] = times_df['income'].astype(float)\n",
        "times_df['total_score'] = times_df['total_score'].replace('-', np.nan)\n",
        "times_df['total_score'] = times_df['total_score'].astype(float)\n",
        "\n",
        "# fill in na values with mean in the year and impute total score for times data\n",
        "for year in range(2011, 2017):\n",
        "    inter_mean = times_df[times_df['year'] == year].international.mean()\n",
        "    income_mean = times_df[times_df['year'] == year].income.mean()\n",
        "    times_df.ix[(times_df.year == year) & (times_df.international.isnull()), 'international'] = inter_mean\n",
        "    times_df.ix[(times_df.year == year) & (times_df.income.isnull()), 'income'] = income_mean\n",
        "times_df.ix[times_df.total_score.isnull(), 'total_score'] = 0.3*times_df['teaching'] + 0.3*times_df['citations'\n",
        "                        ] + 0.3*times_df['research'] + 0.075*times_df['international'] + 0.025*times_df['income']\n",
        "\n",
        "# Rename columns\n",
        "cwur_df.rename(columns={'institution': 'university_name'}, inplace=True)\n",
        "\n",
        "print(\"Data Cleaned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "02c4bde9-9c54-db89-7652-c75b8abe59b0"
      },
      "outputs": [],
      "source": [
        "# Getting data in appropriate format\n",
        "\n",
        "# replace ranking range to midpoint\n",
        "def mid_rank(rank_string):\n",
        "    rank = re.sub('=', '', rank_string)\n",
        "    rank = rank.split('-')\n",
        "    s = 0\n",
        "    for each in rank:\n",
        "        each = float(each)\n",
        "        s = s + each\n",
        "    return s/len(rank)\n",
        "\n",
        "# replace ranking range for shanghai and times data\n",
        "times_df['world_rank_tidy'] = times_df['world_rank'].apply(mid_rank)\n",
        "shanghai_df['world_rank_tidy'] = shanghai_df['world_rank'].apply(mid_rank)\n",
        "\n",
        "# get unique school and country using times and cwur data \n",
        "# Manually link countries for unique shanghai universities\n",
        "shanghai_schools = pd.DataFrame([['Technion-Israel Institute of Technology', 'Israel'],\n",
        "                   ['Swiss Federal Institute of Technology Lausanne', 'Switzerland']], columns=['university_name', 'country'])\n",
        "school_country = cwur_df.drop_duplicates(['university_name', 'country'])[['university_name', 'country']].append(\n",
        "    times_df.drop_duplicates(['university_name', 'country'])[['university_name', 'country']], ignore_index=True).append(\n",
        "    shanghai_schools, ignore_index=True)\n",
        "school_country['country'].replace(['United States of America', 'United States'], 'USA', inplace=True)\n",
        "school_country['country'].replace(['United Kingdom'], 'UK', inplace=True)\n",
        "\n",
        "# Manually replacing countries which were not present in our pivot for countires - cwur\n",
        "school_country['country'][school_country['university_name'] == 'Technion-Israel Institute of Technology'] = 'Israel'\n",
        "school_country['country'][school_country['university_name'] == 'Swiss Federal Institute of Technology Lausanne'] = 'Switzerland'\n",
        "school_country = school_country.drop_duplicates(['university_name', 'country'])[['university_name', 'country']]\n",
        "school_country = school_country.reset_index(drop=True)\n",
        "\n",
        "# get ranking and score information by year\n",
        "cwur_world_ranking = cwur_df[['university_name', 'country', 'world_rank', 'year']]\n",
        "cwur_world_ranking = cwur_world_ranking.pivot(index = 'university_name', columns = 'year')['world_rank']\n",
        "cwur_world_ranking.columns = ['cwur_2012_r', 'cwur_2013_r', 'cwur_2014_r', 'cwur_2015_r']\n",
        "cwur_world_ranking = cwur_world_ranking.reset_index()\n",
        "\n",
        "times_ranking = times_df[['university_name', 'country', 'world_rank_tidy', 'year']]\n",
        "times_ranking = times_ranking.pivot(index = 'university_name', columns = 'year')['world_rank_tidy']\n",
        "times_ranking.columns = ['times_2011_r', 'times_2012_r', 'times_2013_r', 'times_2014_r', 'times_2015_r', 'times_2016_r']\n",
        "times_ranking = times_ranking.reset_index()\n",
        "\n",
        "shanghai_ranking = shanghai_df[['university_name', 'world_rank_tidy', 'year']]\n",
        "for y in range(2005, 2011):\n",
        "    shanghai_ranking = shanghai_ranking[shanghai_ranking.year != y]\n",
        "shanghai_ranking = shanghai_ranking.pivot(index = 'university_name', columns = 'year')['world_rank_tidy']\n",
        "shanghai_ranking.columns = ['sh_2011_r', 'sh_2012_r', 'sh_2013_r', 'sh_2014_r', 'sh_2015_r']\n",
        "shanghai_ranking = shanghai_ranking.reset_index()\n",
        "\n",
        "# join ranking and score for all 3\n",
        "rank_all = pd.merge(cwur_world_ranking, times_ranking, on = 'university_name', how = 'outer')\n",
        "rank_all = pd.merge(rank_all, shanghai_ranking, on = 'university_name', how = 'outer')\n",
        "rank_all = pd.merge(rank_all, school_country, on = 'university_name', how = 'left')\n",
        "\n",
        "rank_all.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cde07d31-0568-b67e-e206-d32a16f89140"
      },
      "source": [
        "### Part 2 - Preparing data for analysis\n",
        "\n",
        "We shall consider the top 100 Universities for each ranking system for the year 2014 and then merge them together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f445dd45-913d-5421-24d3-0087ec3f2587"
      },
      "outputs": [],
      "source": [
        "# Merging relevant data and computing pairwise ranking system difference for each university\n",
        "# For universities which are not common in all ranking system, I am imputing a rank of 700\n",
        "\n",
        "# Taking top 100 colleges from 3 ranking systems for the year 2015\n",
        "top = 150\n",
        "rank_analysis = rank_all[['university_name','country', 'times_2014_r', 'cwur_2014_r', 'sh_2014_r']]\n",
        "ra_t = rank_analysis.sort_values(by='times_2014_r').head(top)\n",
        "ra_c = rank_analysis.sort_values(by='cwur_2014_r').head(top)\n",
        "ra_s = rank_analysis.sort_values(by='sh_2014_r').head(top)\n",
        "\n",
        "# Rename columns\n",
        "ra_c.rename(columns={'country': 'country_c', 'times_2014_r': 'times_2014_r_c',\n",
        "                     'cwur_2014_r': 'cwur_2014_r_c', 'sh_2014_r': 'sh_2014_r_c'}, inplace=True)\n",
        "ra_s.rename(columns={'country': 'country_s', 'times_2014_r': 'times_2014_r_s',\n",
        "                     'cwur_2014_r': 'cwur_2014_r_s', 'sh_2014_r': 'sh_2014_r_s'}, inplace=True)\n",
        "\n",
        "# Merging the data based on top 100 universities from each ranking\n",
        "rank_analysis_sct = pd.merge(ra_t, \n",
        "                             pd.merge(ra_c, \n",
        "                              ra_s, on = 'university_name', how = 'outer'), \n",
        "                                    on = 'university_name', how = 'outer')\n",
        "\n",
        "# Ensuring country column is not blank for universities not present in all 3 rankings\n",
        "for i in range(len(rank_analysis_sct)):\n",
        "    if pd.isnull(rank_analysis_sct.loc[i, 'country']):\n",
        "        rank_analysis_sct.loc[i, 'country'] = str(rank_analysis[rank_analysis['university_name'] ==\n",
        "            rank_analysis_sct.loc[i, 'university_name']].iloc[0]['country'])\n",
        "\n",
        "\n",
        "# Ensuring rank column is not blank for universities not present in all 3 rankings\n",
        "rank_analysis_sct['times_2014_r'] = rank_analysis_sct['times_2014_r'].replace(np.nan, rank_analysis_sct['times_2014_r_c'])\n",
        "rank_analysis_sct['times_2014_r'] = rank_analysis_sct['times_2014_r'].replace(np.nan, rank_analysis_sct['times_2014_r_s'])\n",
        "\n",
        "rank_analysis_sct['cwur_2014_r'] = rank_analysis_sct['cwur_2014_r'].replace(np.nan, rank_analysis_sct['cwur_2014_r_c'])\n",
        "rank_analysis_sct['cwur_2014_r'] = rank_analysis_sct['cwur_2014_r'].replace(np.nan, rank_analysis_sct['cwur_2014_r_s'])\n",
        "\n",
        "rank_analysis_sct['sh_2014_r'] = rank_analysis_sct['sh_2014_r'].replace(np.nan, rank_analysis_sct['sh_2014_r_c'])\n",
        "rank_analysis_sct['sh_2014_r'] = rank_analysis_sct['sh_2014_r'].replace(np.nan, rank_analysis_sct['sh_2014_r_s'])\n",
        "\n",
        "# Replacing nan items (universities which do not exist in ranking) with rank of 700 to ensure they are at farther distance\n",
        "rank_analysis_sct['times_2014_r'] = rank_analysis_sct['times_2014_r'].replace(np.nan, 700).astype(int)\n",
        "rank_analysis_sct['cwur_2014_r'] = rank_analysis_sct['cwur_2014_r'].replace(np.nan, 700).astype(int)\n",
        "rank_analysis_sct['sh_2014_r'] = rank_analysis_sct['sh_2014_r'].replace(np.nan, 700).astype(int)\n",
        "\n",
        "# Selecting only required columns\n",
        "rank_analysis_sct = rank_analysis_sct[['university_name', 'country', \n",
        "                                        'times_2014_r', 'cwur_2014_r', 'sh_2014_r']]\n",
        "\n",
        "# Creating columns for difference in ranking for each pair\n",
        "rank_analysis_sct['t_c'] = rank_analysis_sct['times_2014_r'] - rank_analysis_sct['cwur_2014_r']\n",
        "rank_analysis_sct['t_s'] = rank_analysis_sct['times_2014_r'] - rank_analysis_sct['sh_2014_r']\n",
        "rank_analysis_sct['c_s'] = rank_analysis_sct['cwur_2014_r'] - rank_analysis_sct['sh_2014_r']\n",
        "\n",
        "rank_analysis_sct.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8c1225c1-9d7a-970e-286f-028cc00cafe4"
      },
      "source": [
        "### Part 3 - Cluster Analysis\n",
        "\n",
        "In this section we will analyze whether universities in each ranking system can be clustered based on how different the rankings are in relation to the other ranking systems (pairwise).\n",
        "\n",
        "We will see if a distinction between the 5 groups given below can be done based on clustering algorithm:\n",
        "\n",
        "1. University heavily biased towards ranking system 1\n",
        "\n",
        "2. University slightly biased towards ranking system 1\n",
        "\n",
        "3. University in ranking system 1 and ranking system 2 not biased\n",
        "\n",
        "4. University slightly biased towards ranking system 2\n",
        "\n",
        "5. University heavily biased towards ranking system 2\n",
        "\n",
        "We will also verify our clustering results by comparing it to logical results (based on hard coded values for each of the 5 groups above)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8dc1c824-1936-ef84-1dfc-34b406a6c14b"
      },
      "outputs": [],
      "source": [
        "# Checking the distribution of pairwise ranking difference\n",
        "\n",
        "fig, ax = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(12, 6))\n",
        "fig.text(0.04, 0.5, 'Number of Universities', va='center', rotation='vertical', fontsize =15)\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.hist(rank_analysis_sct.t_c, color = 'purple', alpha = 0.4, range=[-400,800], bins=(25))\n",
        "plt.axvline(0, color = 'purple', linestyle = 'dashed', linewidth = 2)\n",
        "plt.xlabel('Times & CWUR')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.hist(rank_analysis_sct.t_s, color = 'purple', alpha = 0.4, range=[-400,800], bins=(25))\n",
        "plt.axvline(0, color = 'purple', linestyle = 'dashed', linewidth = 2)\n",
        "plt.xlabel('Times & Shanghai')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.hist(rank_analysis_sct.c_s, color = 'purple', alpha = 0.4, range=[-400,800], bins=(25))\n",
        "plt.axvline(0, color = 'purple', linestyle = 'dashed', linewidth = 2)\n",
        "plt.xlabel('CWUR & Shanghai')\n",
        "\n",
        "plt.suptitle(\"Distribution of pairwise ranking difference\", fontsize=20)\n",
        "\n",
        "plt.savefig('plot_all_hist.jpg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "df9b216c-627a-bd65-1bb6-374977d1cbba"
      },
      "source": [
        "The pairwise ranking distances look more or less normally distributed. Now let us start with clustering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3a855fd3-2278-990c-a888-2c2a868f010d"
      },
      "outputs": [],
      "source": [
        "# Function to create logical clusters by hardcoding group memberships\n",
        "# The groups are\n",
        "# 1. University heavily biased towards ranking system 1 -> Pairwise difference greater than 216\n",
        "# 2. University slightly biased towards ranking system 1 -> Diff less than 216 greater than 50\n",
        "# 3. University in ranking system 1 and ranking system 2 not biased -> Pairwise diff less than +/- 50\n",
        "# 4. University slightly biased towards ranking system 2 -> Diff greater than -216 less than -50\n",
        "# 5. University heavily biased towards ranking system 2 -> Pairwise difference lesser than -216\n",
        "\n",
        "def logical_cluster(pair_col, logical_cluster_col):\n",
        "    rank_analysis_sct[logical_cluster_col] = 0\n",
        "    for i in range(len(rank_analysis_sct)):\n",
        "        if rank_analysis_sct.loc[i,pair_col] < -216: rank_analysis_sct.loc[i,logical_cluster_col] = 0\n",
        "        elif rank_analysis_sct.loc[i,pair_col] < -50 and rank_analysis_sct.loc[i,pair_col] >= -216:\n",
        "            rank_analysis_sct.loc[i,logical_cluster_col] = 1\n",
        "        elif rank_analysis_sct.loc[i,pair_col] > -50 and rank_analysis_sct.loc[i,pair_col] < 50:\n",
        "            rank_analysis_sct.loc[i,logical_cluster_col] = 2\n",
        "        elif rank_analysis_sct.loc[i,pair_col] > 50 and rank_analysis_sct.loc[i,pair_col] <= 216:\n",
        "            rank_analysis_sct.loc[i,logical_cluster_col] = 3\n",
        "        elif rank_analysis_sct.loc[i,pair_col] > 216: rank_analysis_sct.loc[i,logical_cluster_col] = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c545e167-42e1-15d0-6f49-b9dc88f587e7"
      },
      "outputs": [],
      "source": [
        "# Creating logical clusters based on intervals obtained after eyeballing the data\n",
        "logical_cluster('t_c', 't_c_cluster_logical')\n",
        "logical_cluster('t_s', 't_s_cluster_logical')\n",
        "logical_cluster('c_s', 'c_s_cluster_logical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7e64276e-ea21-abaa-547a-793dbaf69d4a"
      },
      "source": [
        "#### Here we have created pairwise logical clusters after eyeballing our data. This will give us a good measure of testing our clustering algorithm.\n",
        "\n",
        "#### Now let us cluster using kmeans clustering algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "afa9220c-6275-d6c6-173f-9f0edc9a6b0d"
      },
      "outputs": [],
      "source": [
        "# Function to create K-means cluster\n",
        "def kmeans_cluster(pair_col, knn_cluster_col, order):\n",
        "    model = KMeans(n_clusters=5)\n",
        "    k_mean = rank_analysis_sct[[pair_col]]\n",
        "    model.fit(k_mean)\n",
        "    pred = np.choose(model.labels_, order).astype(np.int64)  # Assigning correct labels\n",
        "    rank_analysis_sct[knn_cluster_col] = pred  # Adding column of cluster information to dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1e654ab5-9ec5-ec3d-1450-eb8b9f7e44ad"
      },
      "outputs": [],
      "source": [
        "# Creating kmeans clusters\n",
        "np.random.seed(seed=1)\n",
        "kmeans_cluster('t_c', 't_c_cluster_kmeans', [2, 4, 0, 1, 3])\n",
        "kmeans_cluster('t_s', 't_s_cluster_kmeans', [2, 4, 0, 3, 1])\n",
        "kmeans_cluster('c_s', 'c_s_cluster_kmeans', [2, 0, 1, 4, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "95279454-407b-78a8-a6ad-bf2e7f4016a1"
      },
      "outputs": [],
      "source": [
        "# Function to create scatter plot for pairwise clustering results\n",
        "def bias_scatter(colormap, rank_diff, cluster, r1, r2, typ):  \n",
        "    plt.scatter(rank_diff, rank_diff, c=colormap[cluster], s=40, alpha=0.6)\n",
        "    plt.title('University Bias - '+ r1 + ' vs ' + r2 + ' (' + typ + ')', fontsize = 15)\n",
        "    plt.xlabel('Difference')\n",
        "    plt.ylabel('Difference')\n",
        "    b1 = mpatches.Patch(color=colormap[0], label='Highly Favored by' + r1, alpha = 0.7)\n",
        "    b2 = mpatches.Patch(color=colormap[1], label='Favored by' + r1, alpha = 0.7)\n",
        "    b3 = mpatches.Patch(color=colormap[2], label='Neutral', alpha = 0.7)\n",
        "    b4 = mpatches.Patch(color=colormap[3], label='Favored by' + r2, alpha = 0.7)\n",
        "    b5 = mpatches.Patch(color=colormap[4], label='Highly Favored by Times' +r2, alpha = 0.7)\n",
        "    plt.legend(handles=[b1, b2, b3, b4, b5], loc = 2)\n",
        "\n",
        "    #plt.savefig('LogicalVsKMean.jpg')\n",
        "    #plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "24dbeb61-c2ea-72bc-140c-28eccd97018d"
      },
      "outputs": [],
      "source": [
        "# Plotting scatterplot\n",
        "colormap_tc = np.array(['navy', 'skyblue', 'black','palegreen', 'green'])\n",
        "colormap_ts = np.array(['navy', 'skyblue', 'black','coral', 'darkred'])\n",
        "colormap_cs = np.array(['green', 'palegreen', 'black','coral', 'darkred'])\n",
        "\n",
        "plt.figure(figsize=(12,22))\n",
        "plt.subplot(3, 2, 1)\n",
        "bias_scatter(colormap_tc, rank_analysis_sct.t_c, rank_analysis_sct['t_c_cluster_logical'], 'Times', 'CWUR', 'Logical')\n",
        "plt.subplot(3, 2, 2)\n",
        "bias_scatter(colormap_tc, rank_analysis_sct.t_c, rank_analysis_sct['t_c_cluster_kmeans'], 'Times', 'CWUR', 'K-means')\n",
        "plt.subplot(3, 2, 3)\n",
        "bias_scatter(colormap_ts, rank_analysis_sct.t_s, rank_analysis_sct['t_s_cluster_logical'], 'Times', 'Shanghai', 'Logical')\n",
        "plt.subplot(3, 2, 4)\n",
        "bias_scatter(colormap_ts, rank_analysis_sct.t_s, rank_analysis_sct['t_s_cluster_kmeans'], 'Times', 'Shanghai', 'K-means')\n",
        "plt.subplot(3, 2, 5)\n",
        "bias_scatter(colormap_cs, rank_analysis_sct.c_s, rank_analysis_sct['c_s_cluster_logical'], 'CWUR', 'Shanghai', 'Logical')\n",
        "plt.subplot(3, 2, 6)\n",
        "bias_scatter(colormap_cs, rank_analysis_sct.c_s, rank_analysis_sct['c_s_cluster_kmeans'], 'CWUR', 'Shanghai', 'K-means')\n",
        "plt.savefig('plot_clusters_scatter.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2273a423-bd83-099f-14a2-42ff21ad5478"
      },
      "source": [
        "We see that the logical and machine learning results are very similar. Let us visualize these same results using a barplot to give us a better idea."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "340d78c1-60a4-6d48-ee90-3f690583c3bf"
      },
      "outputs": [],
      "source": [
        "# Function to create barplot for pairwise clustering results\n",
        "def bias_bar(logical_col, knn_col, cm, r1, r2):\n",
        "    logical_bias = rank_analysis_sct.groupby(logical_col).count()['university_name']\n",
        "    kmeans_bias = rank_analysis_sct.groupby(knn_col).count()['university_name']\n",
        "    \n",
        "    x = logical_bias.index\n",
        "    y1 = logical_bias.values\n",
        "    y2 = kmeans_bias\n",
        "    bar_width = 0.35\n",
        "    opacity = 0.7\n",
        "    \n",
        "    rects1 = plt.bar([x[0], x[0]+0.4], [y1[0], y2[0]], bar_width,  alpha=opacity, color=cm[0], label='High Favor: ' + r1)\n",
        "    rects2 = plt.bar([x[1], x[1]+0.4], [y1[1], y2[1]], bar_width, alpha=opacity, color=cm[1], label='Favor: ' + r1)\n",
        "    rects3 = plt.bar([x[2], x[2]+0.4], [y1[2], y2[2]], bar_width, alpha=opacity, color=cm[2], label='Neutral')\n",
        "    rects4 = plt.bar([x[3], x[3]+0.4], [y1[3], y2[3]], bar_width, alpha=opacity, color=cm[3], label='Favor: ' + r2)\n",
        "    rects5 = plt.bar([x[4], x[4]+0.4], [y1[4], y2[4]], bar_width, alpha=opacity, color=cm[4], label='High favor: ' + r2)\n",
        "\n",
        "    plt.text(x[0], y1[0], y1[0], ha='center', va='bottom', size=10)\n",
        "    plt.text(x[1], y1[1], y1[1], ha='center', va='bottom', size=10)\n",
        "    plt.text(x[2], y1[2], y1[2], ha='center', va='bottom', size=10)\n",
        "    plt.text(x[3], y1[3], y1[3], ha='center', va='bottom', size=10)\n",
        "    plt.text(x[4], y1[4], y1[4], ha='center', va='bottom', size=10)\n",
        "    \n",
        "    plt.text(x[0] + bar_width, y2[0], y2[0], ha='center', va='bottom', size=10)\n",
        "    plt.text(x[1] + bar_width, y2[1], y2[1], ha='center', va='bottom', size=10)\n",
        "    plt.text(x[2] + bar_width, y2[2], y2[2], ha='center', va='bottom', size=10)\n",
        "    plt.text(x[3] + bar_width, y2[3], y2[3], ha='center', va='bottom', size=10)\n",
        "    plt.text(x[4] + bar_width, y2[4], y2[4], ha='center', va='bottom', size=10)\n",
        "\n",
        "    plt.xlabel('Bias')\n",
        "    plt.ylabel('Univesities')\n",
        "    #plt.title('Bias in University Pairs')\n",
        "    plt.xticks(x + bar_width, ('Logical / KMeans', 'Logical / KMeans',\n",
        "                               'Logical / KMeans', 'Logical / KMeans', 'Logical / KMeans'))\n",
        "\n",
        "    plt.legend()\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "809547e5-4d36-ea07-2593-1892b7e0940e"
      },
      "outputs": [],
      "source": [
        "# Plotting barplot\n",
        "plt.figure(figsize=(9,12))\n",
        "plt.subplot(3, 1, 1)\n",
        "bias_bar('t_c_cluster_logical', 't_c_cluster_kmeans', colormap_tc, 'Times', 'CWUR')\n",
        "plt.subplot(3, 1, 2)\n",
        "bias_bar('t_s_cluster_logical', 't_s_cluster_kmeans', colormap_ts, 'Times', 'Shanghai')\n",
        "plt.subplot(3, 1, 3)\n",
        "bias_bar('c_s_cluster_logical', 'c_s_cluster_kmeans', colormap_cs, 'CWUR', 'Shanghai')\n",
        "plt.savefig('plot_clusters_bar.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0a5471df-a767-586e-a278-d68652f5a4d2"
      },
      "source": [
        "From the barplots we can confirm that the logical and KMeans clustering results are similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "19d3e329-eef3-75ae-45a5-234a60f7ec46"
      },
      "outputs": [],
      "source": [
        "# Comparing K-mean classification to logical classification\n",
        "y = rank_analysis_sct.t_c_cluster_logical\n",
        "\n",
        "# Performance Metrics\n",
        "print('Accuracy',sm.accuracy_score(y, rank_analysis_sct['t_c_cluster_kmeans']))\n",
        "\n",
        "# Confusion Matrix\n",
        "sm.confusion_matrix(y, rank_analysis_sct['t_c_cluster_kmeans'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "274cebc7-b648-2688-145b-c2ca0ed40bbb"
      },
      "source": [
        "#### 89% Accuracy rate of confusion matrix is pretty good (especially considering we just eyeballed the data to hard-code initial clusters) so will maintain the KMean model to cluster pairwise ranking systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a72a4973-f45b-dd4c-b553-6553750ed922"
      },
      "source": [
        "#### These plots help us visualize the count of Universities for which there is underlying bias between any 2 ranking systems as well as understand in which form the bias exists.\n",
        "\n",
        "#### Now let us aggregate the result for each University."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "963d1a53-b45a-8455-cff8-cf97056680da"
      },
      "outputs": [],
      "source": [
        "# Creating binary columns to determine if 2 systems agree on the ranking of University (based on cluster)\n",
        "for i in range(len(rank_analysis_sct)):\n",
        "    if rank_analysis_sct.loc[i,'t_c_cluster_kmeans'] in [1,2,3]: rank_analysis_sct.loc[i,'t_c_proximity'] = 1\n",
        "    else: rank_analysis_sct.loc[i,'t_c_proximity'] = 0\n",
        "    if rank_analysis_sct.loc[i,'t_s_cluster_kmeans'] in [1,2,3]: rank_analysis_sct.loc[i,'t_s_proximity'] = 1\n",
        "    else: rank_analysis_sct.loc[i,'t_s_proximity'] = 0\n",
        "    if rank_analysis_sct.loc[i,'c_s_cluster_kmeans'] in [1,2,3]: rank_analysis_sct.loc[i,'c_s_proximity'] = 1\n",
        "    else: rank_analysis_sct.loc[i,'c_s_proximity'] = 0\n",
        "\n",
        "# Creating column for aggregate trustworthiness of all 3 ranking systems for each University\n",
        "# Score of 3 means all 3 ranking sytem pairs agree on ranking of a University and\n",
        "# Score of 0 means that no pair of ranking system agrees on ranking of a University\n",
        "rank_analysis_sct['impartiality_score'] = rank_analysis_sct['t_c_proximity'\n",
        "                                      ] + rank_analysis_sct['t_s_proximity'] + rank_analysis_sct['c_s_proximity']\n",
        "\n",
        "                                                                                                 \n",
        "rank_analysis_sct.to_csv('resultsRankingAnalysis.csv')\n",
        "\n",
        "# Summarizing results\n",
        "assurance_summary = rank_analysis_sct[['university_name', 'impartiality_score']].groupby('impartiality_score').count()\n",
        "assurance_summary.rename(columns={'university_name': 'Total Universities'}, inplace=True)\n",
        "assurance_summary.sort_index(ascending = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "18e5e616-212b-aec2-97c2-ee6b3f5a5ab7"
      },
      "source": [
        "We use a metric called 'impartiality score' to aggregate our clustering results.\n",
        "\n",
        "171 Universities have an impartiality score of 3. This means that these 171 universities have similar rankings across all ranking systems which means that all ranking systems are impartial towards them. 31 (14+17) Universities have an impartiality score of either 2 or 3 which means that these universities have very different rankings across all ranking systems. This means one or two of the the ranking systems are biased towards/against them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f7416837-88b2-9627-e3c7-a5c31ea39a45"
      },
      "source": [
        "### Part 4 - Checking for bias in ranking system owing to countries\n",
        "\n",
        "First let us see how the distribution of countries in the ranking systems looks like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d297553a-e7f6-a5d2-6232-b2b0137a8617"
      },
      "outputs": [],
      "source": [
        "# Preparing data for analyzing country bias\n",
        "country_bias = pd.DataFrame(rank_analysis_sct.groupby('country').count().sort_values(by=\n",
        "                                      'university_name',ascending = False)['university_name'])\n",
        "country_bias = pd.DataFrame(list(country_bias['university_name'].values),\n",
        "                            list(country_bias['university_name'].index))\n",
        "country_bias.rename(columns={0: 'Total Universities'}, inplace=True)\n",
        "print(country_bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0cffee0c-a6ef-61e1-8fd3-05ef8ffd1965"
      },
      "source": [
        "Here we see the distribution of countries harboring top 100 universities in each ranking system.\n",
        "\n",
        "Now let us check if any ranking system exhibits bias based on country. For the purpose of this analysis, we will assume there is a bias if the difference in ranking is greater than 50 (this is a charitable range given that we are considering the top 100 Universities). Also, we will be considering all countries in this analysis, but the countries which have less than 2 universities in the ranking won't be very significant (and hence won't be displayed) in the final analysis just on account of small sample size.\n",
        "\n",
        "We will be considering both - the bias against Universities from a country as well as the bias towards the universities from a country."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c0079d12-8daa-97d7-e233-90e5338b3e1f"
      },
      "outputs": [],
      "source": [
        "# Creating function to compute bias based on the kmeans cluster affiliation of a university\n",
        "def country_bias_calc(p_kmeans, p, bias_name, country_bias_tab):\n",
        "    pkm1, pkm2 = p_kmeans[0]+'_cluster_kmeans', p_kmeans[1]+'_cluster_kmeans'\n",
        "    \n",
        "    bias_pair = pd.DataFrame(rank_analysis_sct[rank_analysis_sct[pkm1].isin(p[0]) &\n",
        "                                               rank_analysis_sct[pkm2].isin(p[1])\n",
        "                                              ].groupby('country').count()['university_name'])\n",
        "    bias_pair = pd.DataFrame(list(bias_pair['university_name'].values),\n",
        "                             list(bias_pair['university_name'].index))\n",
        "    bias_pair.rename(columns={0: bias_name}, inplace=True)\n",
        "    \n",
        "    if country_bias_tab.empty: tab = country_bias\n",
        "    else: tab = country_bias_tab\n",
        "    country_bias_tab = pd.merge(tab, bias_pair, on=None,left_index=True, right_index=True, \n",
        "                                how = 'left')\n",
        "    country_bias_tab[bias_name] = country_bias_tab[bias_name].replace(np.nan, 0)\n",
        "    country_bias_tab[bias_name + ' %'] = country_bias_tab[bias_name] / country_bias_tab[\n",
        "        'Total Universities'] * 100\n",
        "    return country_bias_tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "262d626d-cd27-7ba3-4166-8c0fd82fc303"
      },
      "outputs": [],
      "source": [
        "# Computing country bias\n",
        "country_bias_f = pd.DataFrame\n",
        "country_bias_a = pd.DataFrame\n",
        "\n",
        "country_bias_f = country_bias_calc(['t_c', 't_s'],[[0,1],[0,1]], 'Times Bias', country_bias_f)\n",
        "country_bias_f = country_bias_calc(['t_c', 'c_s'],[[3,4],[0,1]], 'CWUR Bias', country_bias_f)\n",
        "country_bias_f = country_bias_calc(['t_s', 'c_s'],[[3,4],[3,4]], 'Shanghai Bias', country_bias_f)\n",
        "\n",
        "country_bias_a = country_bias_calc(['t_c', 't_s'],[[3,4],[3,4]], 'Times Bias', country_bias_a)\n",
        "country_bias_a = country_bias_calc(['t_c', 'c_s'],[[0,1],[3,4]], 'CWUR Bias', country_bias_a)\n",
        "country_bias_a = country_bias_calc(['t_s', 'c_s'],[[0,1],[0,1]], 'Shanghai Bias', country_bias_a)\n",
        "\n",
        "# Uncomment below code to check for extreme bias\n",
        "\n",
        "#country_bias_f = country_bias_calc(['t_c', 't_s'],[[0,0],[0,0]], 'Times Bias', country_bias_f)\n",
        "#country_bias_f = country_bias_calc(['t_c', 'c_s'],[[4,4],[0,0]], 'CWUR Bias', country_bias_f)\n",
        "#country_bias_f = country_bias_calc(['t_s', 'c_s'],[[4,4],[4,4]], 'Shanghai Bias', country_bias_f)\n",
        "\n",
        "#country_bias_a = country_bias_calc(['t_c', 't_s'],[[4,4],[4,4]], 'Times Bias', country_bias_a)\n",
        "#country_bias_a = country_bias_calc(['t_c', 'c_s'],[[0,0],[4,4]], 'CWUR Bias', country_bias_a)\n",
        "#country_bias_a = country_bias_calc(['t_s', 'c_s'],[[0,0],[0,0]], 'Shanghai Bias', country_bias_a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c4b8c9cd-e688-9709-7d56-8367b884f44c"
      },
      "outputs": [],
      "source": [
        "country_bias_a.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9274bc48-d5e1-4017-9bf6-d5765231f241"
      },
      "outputs": [],
      "source": [
        "# Breaking the main tables into tables based on rankings to plot\n",
        "t = 15  # Minimumum bias % for us to consider bias\n",
        "u = 2  # Minimum universities in the ranking system to consider bias\n",
        "\n",
        "bias_for_times = country_bias_f[(country_bias_f['Times Bias %'] >= t) & (country_bias_f['Total Universities'] > u)\n",
        "        ].sort_values(by='Times Bias %', ascending = False)[['Total Universities', 'Times Bias', 'Times Bias %']]\n",
        "\n",
        "bias_against_times = country_bias_a[(country_bias_a['Times Bias %'] >= t) & (country_bias_a['Total Universities'] > u)\n",
        "        ].sort_values(by='Times Bias %', ascending = False)[['Total Universities', 'Times Bias', 'Times Bias %']]\n",
        "\n",
        "bias_for_cwur = country_bias_f[(country_bias_f['CWUR Bias %'] >= t) & (country_bias_f['Total Universities'] > u)\n",
        "        ].sort_values(by='CWUR Bias %', ascending = False)[['Total Universities', 'CWUR Bias', 'CWUR Bias %']]\n",
        "\n",
        "bias_against_cwur = country_bias_a[(country_bias_a['CWUR Bias %'] >= t) & (country_bias_a['Total Universities'] > u)\n",
        "        ].sort_values(by='CWUR Bias %', ascending = False)[['Total Universities', 'CWUR Bias', 'CWUR Bias %']]\n",
        "\n",
        "bias_for_shanghai = country_bias_f[(country_bias_f['Shanghai Bias %'] >= t) & (country_bias_f['Total Universities'] > u)\n",
        "        ].sort_values(by='Shanghai Bias %', ascending = False)[['Total Universities', 'Shanghai Bias', 'Shanghai Bias %']]\n",
        "\n",
        "bias_against_shanghai = country_bias_a[(country_bias_a['Shanghai Bias %'] >= t) & (country_bias_a['Total Universities'] > u)\n",
        "        ].sort_values(by='Shanghai Bias %', ascending = False)[['Total Universities', 'Shanghai Bias', 'Shanghai Bias %']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "da007cc8-7839-ba5f-ef16-aa6fb43bb509"
      },
      "outputs": [],
      "source": [
        "# Function to create country bias bar plot\n",
        "def bias_plot(b_for, b_against, b_name):\n",
        "    \n",
        "    def autolabel(rects, ht, m):\n",
        "        cnt = 0\n",
        "        for rect in rects:\n",
        "            height = rect.get_height()\n",
        "            if cnt < len(rects) and rect == rects1[cnt]:\n",
        "                ht.append(height)\n",
        "                cnt+=1\n",
        "                #m.text(rect.get_x() + rect.get_width()/2., \n",
        "                #        height/2-0.5, '%d' % int(height), ha='center', va='bottom', fontsize=12)\n",
        "            else:\n",
        "                #m.text(rect.get_x() + rect.get_width()/2., \n",
        "                #         height/2-0.5, '%d' % int(height), ha='center', va='bottom', fontsize=12)\n",
        "                \n",
        "                if m==ax2 and cnt==0 and height/ht[cnt] > 0.85:\n",
        "                    m.text(rect.get_x() + rect.get_width()/2., \n",
        "                        height-2, '%d' % (height/ht[cnt]*100)+'%', ha='center', va='bottom', fontsize=18)\n",
        "                else:\n",
        "                    m.text(rect.get_x() + rect.get_width()/2., \n",
        "                        height, '%d' % (height/ht[cnt]*100)+'%', ha='center', va='bottom', fontsize=18)\n",
        "                cnt+=1\n",
        "        return ht\n",
        "    \n",
        "    N = len(b_for)\n",
        "    univ_total = np.array(b_for['Total Universities'])\n",
        "    univ_bias_for = np.array(b_for[b_name + ' Bias'])\n",
        "    ind = np.arange(N)\n",
        "    width = 0.35\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(2, figsize = (13,8))\n",
        "    rects1 = ax1.bar(ind, univ_total, width, color='green')\n",
        "    rects2 = ax1.bar(ind + width, univ_bias_for, width, color='lightgreen')\n",
        "    ax1.set_ylabel('Count', fontsize=14)\n",
        "    ax1.set_xticks(ind + width)\n",
        "    ax1.set_xticklabels(b_for.index, fontsize=14)\n",
        "    ax1.legend((rects1[0], rects2[0]), ('Total Universities', \n",
        "                                       'Universities biased for by ' + b_name), loc='upper left')\n",
        "    ax1.spines['right'].set_color('none')\n",
        "    ax1.spines['top'].set_color('none')\n",
        "    ax1.yaxis.set_ticks_position('none')\n",
        "    ax1.xaxis.set_ticks_position('none')\n",
        "\n",
        "    ht = []\n",
        "    ht = autolabel(rects1, ht, ax1)\n",
        "    autolabel(rects2, ht, ax1)\n",
        "    \n",
        "    N = len(b_against)\n",
        "    univ_total = np.array(b_against['Total Universities'])\n",
        "    univ_bias_against = np.array(b_against[b_name + ' Bias'])\n",
        "    ind = np.arange(N)\n",
        "    \n",
        "    rects1 = ax2.bar(ind, univ_total, width, color='firebrick')\n",
        "    rects2 = ax2.bar(ind + width, univ_bias_against, width, color='salmon')\n",
        "    ax2.set_ylabel('Count', fontsize=14)\n",
        "    ax2.set_xticks(ind + width)\n",
        "    ax2.set_xticklabels(b_against.index, fontsize=14)\n",
        "    ax2.legend((rects1[0], rects2[0]), ('Total Universities',\n",
        "                                       'Universities biased against by ' + b_name), loc='upper left')\n",
        "    ax2.spines['right'].set_color('none')\n",
        "    ax2.spines['top'].set_color('none')\n",
        "    ax2.yaxis.set_ticks_position('none')\n",
        "    ax2.xaxis.set_ticks_position('none')\n",
        "\n",
        "    ht = []\n",
        "    ht = autolabel(rects1, ht, ax2)\n",
        "    autolabel(rects2, ht, ax2)\n",
        "    \n",
        "    plt.suptitle('Country-wise bias towards(green) and against(red) universities - ' + b_name, fontsize=20)\n",
        "    plt.savefig('plot_'+b_name+'_bias.jpg')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e7fd624d-baf1-b513-630c-d172c02c2648"
      },
      "outputs": [],
      "source": [
        "# Computing country bias for each ranking system pair\n",
        "bias_plot(bias_for_times, bias_against_times, 'Times')\n",
        "bias_plot(bias_for_cwur, bias_against_cwur, 'CWUR')\n",
        "bias_plot(bias_for_shanghai, bias_against_shanghai, 'Shanghai')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ff485a30-fb46-0b0b-4867-d7e95f5fbb87"
      },
      "source": [
        "Please note that these results are for the countries which have a minimum of 2 universities in the ranking systems and a minimum of 15% bias based on countries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5d764e88-9d4f-5e4e-0516-53604427dc1f"
      },
      "source": [
        "In conclusion, we can say that CWUR shows minimum bias TOWARDS universities based on the country of the university but shows maximum bias AGAINST universities based on their countries. Times shows the second highest bias (considering towards and against bias) whereas Shanghai seems to show some bias based on countries but to a lesser degree compared to the other two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9b550532-0373-3c43-3084-f49e8ce05de2"
      },
      "source": [
        "Analysis by Nelson Dsouza, graduate student at the University of Washington majoring in Data Science.\n",
        "www.linkedin.com/in/nelsondsouza1"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}