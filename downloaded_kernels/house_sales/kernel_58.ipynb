{"cells":[{"metadata":{"_uuid":"712bb0bb80aef5b9574b809b98d468da961b4df4","_cell_guid":"04142a5f-73ab-47b4-90d6-806f06761a35"},"cell_type":"markdown","source":"# House Sales in King County, USA\nhttps://www.kaggle.com/harlfoxem/housesalesprediction/data\n\nMiki Katsuragi"},{"metadata":{"collapsed":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom IPython.display import display\nfrom dateutil.parser import parse\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nimport seaborn as sns\nfrom scipy.stats import norm, skew #for some statistics\nfrom scipy import stats","execution_count":1,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0"},"cell_type":"markdown","source":"### Load data into Pandas data frame"},{"metadata":{"_kg_hide-output":true,"_uuid":"0ed5896e2a6906704c7fc27bfc273f17740911e1","_cell_guid":"f0ca97d2-a77d-46ca-95c4-67ec70e5d9e1","trusted":true},"cell_type":"code","source":"d = pd.read_csv(\"../input/kc_house_data.csv\")\nd.head()","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"8498c07da6134ee4d5a48ce7796ad6fa51932a18","_cell_guid":"07e442f1-a7cb-4422-a990-7f10a48cf74a"},"cell_type":"markdown","source":"## Initial data cleansing"},{"metadata":{"collapsed":true,"_uuid":"a0aa9daefd378face739e0233448f04bf5fb5469","_cell_guid":"ee5e35be-d1fa-43ca-8aa4-0def2dffbe5e","trusted":true},"cell_type":"code","source":"#Convert datetime to year and month\nd['yr_sold'] = pd.to_datetime(d.date).map(lambda x:x.year)\nd['m_sold'] = pd.to_datetime(d.date).map(lambda x:x.month)\n\n#仮説:リノベがあったかなかったかのほうが大事そう\nd['yr_renovated'] = np.array(d['yr_renovated'] != 0)*1\n\n#仮設：yr_builtは築年数に直したほうがよさそう\nd['yr_built']=d['yr_built'].max()-d['yr_built']\n\n# yr_renovated should be converted to binary values since there are too many 0 and year has almost no numeric meaning\nd['yr_renovated'] = np.array(d['yr_renovated'] != 0)*1\n\n#zipcodeを前4桁だけにする\n#d['zipcode']=d['zipcode'].astype(str).map(lambda x:x[0:4])\n#id is not definitely required for this analysis\n#d = d.drop([\"id\",\"date\",\"lat\",\"long\"], axis=1)\n\n#zipcodeのかわりにlat,long使う\nd = d.drop([\"id\",\"date\",\"zipcode\"], axis=1)\n","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"9a62fc655a9217f9e1c1fe713dd2c1abd370b4e8","_cell_guid":"76326a20-aaa2-4ec5-97d0-6045acbf94c3"},"cell_type":"markdown","source":"### Confirm relationships between price and other parameters¶"},{"metadata":{"_uuid":"04f07ecb3ba9af35074ba496ccf96a6024225a64","_cell_guid":"7351ea7b-b2fa-49b2-867e-7074ad3c1e19","trusted":true},"cell_type":"code","source":"# Draw scatter charts\ndf1 = d.iloc[:,:9]\ndf2 = d.iloc[:,[0]+list(range(9,18))]\npd.plotting.scatter_matrix(df1,figsize=(13,13))\nplt.show()\npd.plotting.scatter_matrix(df2,figsize=(13,13))\nplt.show()","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"6430283233545ca796b15ef33a903e9e02ef2d2b","_cell_guid":"c88760a8-f21e-49bb-98c8-20419cb174c1"},"cell_type":"markdown","source":"## Process outliers"},{"metadata":{"_uuid":"86070b41fab6e5b50c559c5df6711ef0bc9b10a4","_cell_guid":"c332fc1e-4828-43a8-ad3e-2eee89607b6d","trusted":true},"cell_type":"code","source":"#sqft_livingとbedroomsに外れ値がありそうなので詳細確認\nfig, ax = plt.subplots()\nax.scatter(x = d['sqft_living'], y = d['price'])\nplt.ylabel('price', fontsize=13)\nplt.xlabel('sqft_living', fontsize=13)\nplt.show()\n\nfig, ax = plt.subplots()\nax.scatter(x = d['bedrooms'], y = d['price'])\nplt.ylabel('price', fontsize=13)\nplt.xlabel('bedrooms', fontsize=13)\nplt.show()","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"77e9b7980dc65ffa13788ae8072c6868f98adb65","_cell_guid":"0756d75a-b383-4f1a-b99d-5513eb46416b"},"cell_type":"markdown","source":"どちらも右下に価格の割に大きすぎるsqft_lotが見られる。外れ値と思われるため除外"},{"metadata":{"collapsed":true,"_uuid":"e4c283a15c637e6bbe0d0249aa44d01e5eee9203","_cell_guid":"c723bad7-ee98-4a75-9014-496b8e197437","trusted":true},"cell_type":"code","source":"#Deleting outliers\nd = d.drop(d[(d['sqft_living']>12000) & (d['price']<3000000)].index)\nd = d.drop(d[(d['bedrooms']>30) & (d['price']<2000000)].index)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"8848ca5a71eff69a1d92207b8662cd9d326df297","_cell_guid":"501ab43d-a99d-4e13-bb42-52ed1d4a4833"},"cell_type":"markdown","source":"##目的変数の分布確認"},{"metadata":{"_uuid":"73a09829e09f361f61d10c7dfc67b5278e5a94c5","_cell_guid":"0eed755e-cb38-4338-9cb7-dd267cf2b0e6","trusted":true},"cell_type":"code","source":"sns.distplot(d['price'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(d['price'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(d['price'], plot=plt)\nplt.show()","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"fc1c47a91063ae96185b6d707d663030159f5b9a","_cell_guid":"88b70a34-35e3-4049-ac3d-d70e9e63ff65"},"cell_type":"markdown","source":"価格は右に型が長い分布で正規分布ではなさそう。線形回帰に対応するため正規分布に変換"},{"metadata":{"_uuid":"e5b0acb93880fe4fa0bbae11c6b9778c6b2df6d6","_cell_guid":"686d4d98-a556-49dc-b94b-1982681a3835","trusted":true},"cell_type":"code","source":"#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\nd[\"price\"] = np.log1p(d[\"price\"])\n\n#Check the new distribution \nsns.distplot(d['price'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(d['price'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(d['price'], plot=plt)\nplt.show()","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"0563a5edf2632190889e1a8fe2b89a7d9426445c","_cell_guid":"574d839e-f231-4c3a-8d84-7ea8ba86e27e"},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{"_uuid":"0c38934799cb2961da055c4a5c485b062f132e29","_cell_guid":"6ce79ba8-b119-4d98-a8b6-a1bb840c9034","trusted":true},"cell_type":"code","source":"# Confirm missing values\n#print(d.isnull().any())\npd.DataFrame(d.isnull().sum(), columns=[\"num of missing\"])","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"f0042713c114114e286227da0956814d28a95caa","_cell_guid":"8aa6fc84-37e9-4130-b2cd-0e83f23fd856"},"cell_type":"markdown","source":"It looks like the data has no missing values which means you do not have to worry about it:)"},{"metadata":{"_uuid":"7e67a5e26bf26dcdf9de329301ed91d1484187ee","_cell_guid":"d70a6b54-d462-4185-8718-a93c654a6e13"},"cell_type":"markdown","source":"### Variables which will well explain price values.\nprice shoud be highly correlated with sqft_living, grade, sqft_above, sqft_living15\n\nThat said, following parameters seem to have multicollinearity so let's check VIF.<br>\nbathrooms + sqft_living<br>\ngrade + sqft_above + sqft_living15"},{"metadata":{"_uuid":"20451a8591c0b53ea001e32285c8b1eb51235e62","_cell_guid":"5ac6b9b3-a1ec-4055-b338-4a166815dac2","trusted":true},"cell_type":"code","source":"#Correlation map to see how features are correlated with SalePrice\ncorrmat = d.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corrmat, vmax=0.9, square=True)","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"5a0b8a959d6554a9c818fad4de1217ae8756fcc1","_cell_guid":"7a7a126e-5dde-4bf4-95fc-57e5bdf07dea","trusted":true},"cell_type":"code","source":"#VIFの計算\nfor cname in d.columns:  \n    y=d[cname]\n    X=d.drop(cname, axis=1)\n    regr = LinearRegression(fit_intercept=True)\n    regr.fit(X, y)\n    rsquared = regr.score(X,y)\n    print(cname,\":\" ,1/(1-np.power(rsquared,2)))","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"73e905490038038b182233411c475cc3774fd678","_cell_guid":"f0864083-aa26-41eb-b663-c12b2a36e91a"},"cell_type":"markdown","source":"sqft_living and sqft_above has multicollinearity so I would remove sqft_above from the dataset."},{"metadata":{"_uuid":"58ce65bf388def1301f80472917fd836a7242e00","_cell_guid":"01f5c9de-c22d-4d27-980d-c75e515f2263","trusted":true},"cell_type":"code","source":"d = d.drop(['sqft_above'], axis=1)\nfor cname in d.columns:  \n    y=d[cname]\n    X=d.drop(cname, axis=1)\n    regr = LinearRegression(fit_intercept=True)\n    regr.fit(X, y)\n    rsquared = regr.score(X,y)\n    print(cname,\":\" ,1/(1-np.power(rsquared,2)))","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"3316605606af8bdfe25ddf5a12a7f63486b3ce76","_cell_guid":"4a05186e-88ab-470e-97f3-74c94ebb916a"},"cell_type":"markdown","source":"The result shows no multicollinearity finally so let's try the simple linear regression result."},{"metadata":{"_uuid":"9f6ce6565d9ddec6133997bbd1b5b4c6faef582e","_cell_guid":"1607f4f7-f3fd-45f5-8c06-b3be231999aa","trusted":true},"cell_type":"code","source":"X = d.drop(['price'],axis=1)\ny = d['price']\nregr = LinearRegression(fit_intercept=True).fit(X,y)\nregr = LinearRegression(fit_intercept=True)\nregr.fit(X, y)\nprint(\"決定係数=%s\"%regr.score(X,y))\nprint(\"傾き=%s\"%regr.coef_,\"切片=%s\"%regr.intercept_)\npd.Series(regr.coef_,index=X.columns).sort_values()\\\n  .plot(kind='barh',figsize=(6,8))","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"e62b4ae42a638b33bd9a1334918d17967c7a4ab7","_cell_guid":"088e6a72-cf90-4d54-970f-f7a8fcbc9718"},"cell_type":"markdown","source":"As mentioned above, waterfront is highly correlated with the price and surprisingly lat shows strong impact. gradee, long, view, yr_renovated_bin, bathroooms and conditions are also important things to determine the price. "},{"metadata":{"_uuid":"2c649a82a505ee692ecf83655abd68106f39dc0c","_cell_guid":"8bff537a-2866-443c-aa05-005df6d38c76"},"cell_type":"markdown","source":"### AIC comparison between each models"},{"metadata":{"collapsed":true,"_uuid":"889a8ecc98284f48bf2d253f01b5919ff3221c4f","_cell_guid":"f3eada43-2cc0-4332-836c-dc3e4493c2f2","trusted":true},"cell_type":"code","source":"def step_aic(model, exog, endog, **kwargs):\n    \"\"\"\n    This select the best exogenous variables with AIC Both exog and endog values can be either str or list. (Endog list is for the Binomial family.)\n    \"\"\"\n\n    # Convert　exog, endog　into list\n    exog = np.r_[[exog]].flatten()\n    endog = np.r_[[endog]].flatten()\n    remaining = set(exog)\n    selected = []  # The parameters which choosed the model\n\n    #　AIC for only constant term\n    formula_head = ' + '.join(endog) + ' ~ '\n    formula = formula_head + '1'\n    aic = model(formula=formula, **kwargs).fit().aic\n    print('AIC: {}, formula: {}'.format(round(aic, 3), formula))\n    current_score, best_new_score = np.ones(2) * aic\n\n    # If AIC is not changed any more terminate the process\n    while remaining and current_score == best_new_score:\n        scores_with_candidates = []\n        for candidate in remaining:\n\n            # Calculate the AIC, appending the each parameters\n            formula_tail = ' + '.join(selected + [candidate])\n            formula = formula_head + formula_tail\n            aic = model(formula=formula, **kwargs).fit().aic\n            print('AIC: {}, formula: {}'.format(round(aic, 3), formula))\n\n            scores_with_candidates.append((aic, candidate))\n\n        # Define the best candidate which has the lowest AIC\n        scores_with_candidates.sort()\n        scores_with_candidates.reverse()\n        best_new_score, best_candidate = scores_with_candidates.pop()\n\n        # If the new AIC score is lower than the potential best score, update the best score with the new parameter\n        if best_new_score < current_score:\n            remaining.remove(best_candidate)\n            selected.append(best_candidate)\n            current_score = best_new_score\n\n    formula = formula_head + ' + '.join(selected)\n    print('The best formula: {}'.format(formula))\n    return model(formula, **kwargs).fit()","execution_count":14,"outputs":[]},{"metadata":{"_kg_hide-output":true,"_uuid":"9443d2204204044c86b8281979eb16a817acd583","_cell_guid":"c86fb6d9-606c-4ac8-b7ac-79070a1a5540","trusted":true},"cell_type":"code","source":"'''import statsmodels.formula.api as smf\nmodel = step_aic(smf.ols, ['bedrooms', 'bathrooms', 'sqft_living',\n       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n       'sqft_basement', 'yr_built', 'yr_renovated_bin', \n       'lat', 'long', 'sqft_living15','sqft_lot15'], ['price'],\n      data=d)","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"a990615b776f532a9cd46fc9953c5b4992409352","_cell_guid":"3547c56a-b70b-445f-a930-8b5006b2a4b4"},"cell_type":"markdown","source":"The best formula: <br>\nprice ~ sqft_living + lat + view + grade + yr_built + waterfront + bedrooms + bathrooms + condition + sqft_basement + long + sqft_living15 + yr_renovated_bin + sqft_lot15 + sqft_lot <br>\nwhich means floor is not an important parameter."},{"metadata":{"_kg_hide-output":true,"collapsed":true,"_uuid":"dac622a13050cc7e124b35c331e0563d52f4117b","_cell_guid":"7ddf151d-0e83-4819-9faf-9f9c2f098966","trusted":true},"cell_type":"code","source":"X = d.drop(['floors'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"cc62893e785d91363d14dfa08604de351c325dd3","_cell_guid":"51ab4c55-f6cc-4a16-993a-b0de260ae42a","trusted":true},"cell_type":"code","source":"#d['zipcode'] = d['zipcode'].apply(str)\nd['bathrooms'] = d['bathrooms'].apply(int)\nd['floors'] = d['floors'].apply(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"067c4140ab3765fec0290a01bd54f3e0c53644f8","_cell_guid":"98f690ef-1327-4678-b372-e3ebeffd8550"},"cell_type":"markdown","source":"分布の歪みを補正"},{"metadata":{"_uuid":"3ace37b3f6d579dba302561126799709169d8275","_cell_guid":"f0a517db-90cd-4173-ac0e-40335e3788c4"},"cell_type":"markdown","source":"対象変数に Box Cox 変換実施"},{"metadata":{"collapsed":true,"_uuid":"16acc969b23130547bef73e947b588a1eec8dda9","_cell_guid":"29b93f27-0c1a-410c-aafd-a137faf6a480","trusted":true},"cell_type":"code","source":"# Check the skew of all numerical features\nfrom scipy.stats import norm, skew \nnumeric_feats = d.dtypes[d.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats = d[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6be36170e9067520778e06b05a768b622bc907d2","_cell_guid":"13303f3b-eb5a-4870-abab-8faf2a65b3ec"},"cell_type":"markdown","source":"## cross validation"},{"metadata":{"collapsed":true,"_uuid":"30a624339d7a75d2d33547d321ffa1daadacac73","_cell_guid":"203075d4-3cbd-480a-95e2-6d13116eb5aa","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\n#まずは普通に推定\n\nX_train,X_test,y_train,y_test = train_test_split(np.array(X),np.array(y),test_size=0.2,random_state=42)\n\n# 必要なライブラリのインポート\nfrom sklearn.ensemble import RandomForestRegressor\n# モデル構築、パラメータはデフォルト\nforest = RandomForestRegressor()\nforest.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"8d6f9c5a2ff0526af1949bb4c9227cdd5b3cb2d7","_cell_guid":"722045ef-e648-4b26-b30b-864157cf2b95","trusted":true},"cell_type":"code","source":"# 予測値を計算\ny_train_pred = forest.predict(X_train)\ny_test_pred = forest.predict(X_test)\n\nfrom sklearn.metrics import mean_squared_error\nprint('MSE train : %.3f, test : %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)) )\n\nfrom sklearn.metrics import r2_score\nprint('MSE train : %.3f, test : %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)) )\nprint('MSE train : %.3f, test : %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)) )\nprint('MSE train : %.3f, test : %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)) )\n#mae = mean_absolute_error(y_test, y_pred)\n#print(\"MAE=%s\"%round(mae,3) )","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"b4966afb6aea95b77c7762e0c33e32681bec4c3d","_cell_guid":"f76a1508-4666-4d86-8892-452684bad07a","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n# パラメータ変更\n\nforest = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=25,\n           max_features='auto', max_leaf_nodes=None,\n           min_impurity_decrease=0.0, min_impurity_split=None,\n           min_samples_leaf=1, min_samples_split=5,\n           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n           oob_score=False, random_state=0, verbose=0, warm_start=False)\nforest.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"0630280d24dfd36bbdbcb04a8ad6e7a002b6e5db","_cell_guid":"ecb2e6ba-e40c-4902-8345-69a07f612445","trusted":true},"cell_type":"code","source":"# パラメータチューニング後の予測値を計算\ny_train_pred = forest.predict(X_train)\ny_test_pred = forest.predict(X_test)\n\nfrom sklearn.metrics import mean_squared_error\nprint('MSE train : %.3f, test : %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)) )\n\nfrom sklearn.metrics import r2_score\nprint('MSE train : %.3f, test : %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)) )\nprint('MSE train : %.3f, test : %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)) )\nprint('MSE train : %.3f, test : %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)) )\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d4f51e20769d1019c47e9ce819529577bdba1ba","_cell_guid":"0b7863d6-9b47-41dd-863c-85b5cd3e4677"},"cell_type":"markdown","source":"testの精度が0.01向上"},{"metadata":{"_uuid":"7d04694726151d1b108ba85a3c2a6090bbfb8ce2","_cell_guid":"908fd3c8-ca12-4f67-a444-58552cce5a17"},"cell_type":"markdown","source":"# 他モデルとの比較"},{"metadata":{"_uuid":"f91a2792fe59680f000af25b472c89e78e0b487f","_cell_guid":"9e8f6daf-d096-4814-8b8d-735d35be101c"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"3715d38efac0a0a7d989a83ce2721babbcffd3ff","_cell_guid":"243cc5cb-ab44-4ad0-9eac-963be81b19e8"},"cell_type":"markdown","source":"## Define a cross validation strategy\nWe use the cross_val_score function of Sklearn. However this function has not a shuffle attribut, we add then one line of code, in order to shuffle the dataset prior to cross-validation"},{"metadata":{"collapsed":true,"_uuid":"ebc0236230dd42504623c55698bb91a8389f2940","_cell_guid":"93573f42-28ce-4707-9db6-e5e837214298","trusted":true},"cell_type":"code","source":"#Validation function\nn_folds = 2\n#n_folds = 5\n\n\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train)\n    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"493f6fafc9222e3c26d61f66f00ac337c59f69e3","_cell_guid":"dcfb045d-dc95-4eea-9b1d-5800e2fb5db2"},"cell_type":"markdown","source":"## Base models"},{"metadata":{"collapsed":true,"_uuid":"161d8f49c47170d42079a27eb58bfa4854babde5","_cell_guid":"365d846e-f693-47f7-b829-72673be1b738","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"db44d75e5883d4689432bfde3d06349aed939db7","_cell_guid":"f6435872-4317-4bbe-8be4-b928c6673356","trusted":true},"cell_type":"code","source":"#This model may be very sensitive to outliers. So we need to made it more robust on them. For that we use the sklearn's Robustscaler() method on pipeline\nlasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n#Elastic Net Regression :again made robust to outliers\nENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n#Kernel Ridge Regression:\nKRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n#Gradient Boosting Regression: Gradient Boosting Regression :With huber loss that makes it robust to outliers\nGBoost = GradientBoostingRegressor()\n#XGBoost\nmodel_xgb = xgb.XGBRegressor()\n#LightGBM\nmodel_lgb = lgb.LGBMRegressor()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39ca48a2db7219d967e26dc83db1de9f583c1564","_cell_guid":"dcecf9df-42b9-4298-8a37-12b9d1536583"},"cell_type":"markdown","source":"## Base models scores\nLet's see how these base models perform on the data by evaluating the cross-validation rmsle error"},{"metadata":{"collapsed":true,"_uuid":"c1d2e6de91bc945042682ac185872a876e6d860c","_cell_guid":"41bd8f6a-a6f8-47fe-b91a-ac4f0bd86e5f","trusted":false},"cell_type":"code","source":"'''\nscore = rmsle_cv(lasso)\nprint(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\nscore = rmsle_cv(ENet)\nprint(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\nscore = rmsle_cv(KRR)\nprint(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\nscore = rmsle_cv(GBoost)\nprint(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\nscore = rmsle_cv(model_xgb)\nprint(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\nscore = rmsle_cv(model_lgb)\nprint(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))\n'''","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"1f21f3e13f71d4d8932e01e96b9ef978572a1b1c","_cell_guid":"0aa09e58-4102-4a53-989d-26a4c790a36c"},"cell_type":"markdown","source":"## Stacking models"},{"metadata":{"collapsed":true,"_uuid":"2fad56c646c171ec8719b437517773caf3c75c31","_cell_guid":"9e58f585-3d94-4c38-aaf7-e5a4d31d1fb5"},"cell_type":"markdown","source":"**Averaged base models class**"},{"metadata":{"collapsed":true,"_uuid":"665d2521e7c6c4fbba2be1b2401a67db3edea0ca","_cell_guid":"aebcc9f5-3e39-4515-ac73-07d18c7b7759","trusted":false},"cell_type":"code","source":"'''\nclass AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, models):\n        self.models = models\n        \n    # we define clones of the original models to fit the data in\n    def fit(self, X, y):\n        self.models_ = [clone(x) for x in self.models]\n        \n        # Train cloned base models\n        for model in self.models_:\n            model.fit(X, y)\n\n        return self\n    \n    #Now we do the predictions for cloned models and average them\n    def predict(self, X):\n        predictions = np.column_stack([\n            model.predict(X) for model in self.models_\n        ])\n        return np.mean(predictions, axis=1)   \n        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"456aeaac5a9a611c4f715b60cdb2f40092fc5e8b","_cell_guid":"ec6a8e1b-bb1c-45a2-9e64-870996fb67d0"},"cell_type":"markdown","source":"We just average four models here **ENet, GBoost,  KRR and lasso**.  Of course we could easily add more models in the mix. "},{"metadata":{"collapsed":true,"_uuid":"9603cc210637d5aad5860534ae97d745b6ee147f","_cell_guid":"00d7ddcd-70d8-4dca-8046-339bdd1133c6","trusted":false},"cell_type":"code","source":"'''\naveraged_models = AveragingModels(models = (ENet, GBoost, KRR, lasso))\n\nscore = rmsle_cv(averaged_models)\nprint(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3bf8518257119ea256d497c98289c34ac4745afa","_cell_guid":"ea192d50-483d-4350-8b8a-cf8a5428db54"},"cell_type":"markdown","source":"###  Meta-modelの追加\n上記の平均ベースモデルの予測にメタモデルを追加してトレーニングする。手順は以下の通り\n1. トレーニングセットを2つの別々のセットに分割（例：** train **と** holdout **）\n2. 最初の部分にいくつかの基本モデルを訓練 (**train**)\n3. これらのベースモデルを2番目の部分(**holdout**)でテスト\n4. 入力として3）の予測（out-of-folds予測と呼ぶ）を使用し、** meta-model **と呼ばれるより高いレベルのtrainerを訓練するための出力として正しい目的変数を使用\n最初の3つのステップは繰り返し実行されます。例えば、5回スタッキングする場合、最初にトレーニングデータを5倍に分割します。次に、5回繰り返します。各反復では、すべての基本モデルを4回折りたたみ、残りのを予測\n\nしたがって、5回の反復の後に、データ全体をフォールドアウトの予測に使用し、ステップ4でメタモデルをトレーニングするための新しいフィーチャとして使用することが確実になる。予測部分については、テストデータ上のすべてのベースモデルの予測を平均し、それらを**meta feature**として使用して、最終的な予測をメタモデルで行う。"},{"metadata":{"collapsed":true,"_uuid":"ad2e6f64df1d74f763eb5ef7210a5be9857ddcf8","_cell_guid":"b5e327b2-b3a6-493f-b971-02147065c35a","trusted":false},"cell_type":"code","source":"'''\nclass StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, base_models, meta_model, n_folds=5):\n        self.base_models = base_models\n        self.meta_model = meta_model\n        self.n_folds = n_folds\n   \n    # We again fit the data on clones of the original models\n    def fit(self, X, y):\n        self.base_models_ = [list() for x in self.base_models]\n        self.meta_model_ = clone(self.meta_model)\n        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n        \n        # Train cloned base models then create out-of-fold predictions\n        # that are needed to train the cloned meta-model\n        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n        for i, model in enumerate(self.base_models):\n            for train_index, holdout_index in kfold.split(X, y):\n                instance = clone(model)\n                self.base_models_[i].append(instance)\n                instance.fit(X[train_index], y[train_index])\n                y_pred = instance.predict(X[holdout_index])\n                out_of_fold_predictions[holdout_index, i] = y_pred\n                \n        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n        self.meta_model_.fit(out_of_fold_predictions, y)\n        return self\n   \n    #Do the predictions of all base models on the test data and use the averaged predictions as \n    #meta-features for the final prediction which is done by the meta-model\n    def predict(self, X):\n        meta_features = np.column_stack([\n            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n            for base_models in self.base_models_ ])\n        return self.meta_model_.predict(meta_features)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"2c6776a66547c097f2c42ec924126b2cf4046450","_cell_guid":"8b15159b-bc8e-409c-8e12-cb7a1e995d92","trusted":false},"cell_type":"code","source":"stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n                                                 meta_model = lasso)\n'''\n#重くてコンパイル不可\nscore = rmsle_cv(stacked_averaged_models)\nprint(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b094b0734e44848ecaaf0e81edff4837fa116ea","_cell_guid":"acb64f0d-3616-4887-bd71-c7e844ea71d1"},"cell_type":"markdown","source":"##  XGBoost and LightGBMを追加した累積回帰"},{"metadata":{"_uuid":"71d6bde2a1e31e804420b61f05d865d76cf64070","_cell_guid":"9b649440-3b74-4800-bdcb-9c22ff8f7eab"},"cell_type":"markdown","source":"Add **XGBoost and LightGBM** to the** StackedRegressor** defined previously. "},{"metadata":{"collapsed":true,"_uuid":"251de621348ad9716542b2538b5152fa2132103f","_cell_guid":"33faa984-ac2f-4ac2-be13-e84b91e1f8be","trusted":false},"cell_type":"code","source":"def rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\nstacked_averaged_models.fit(X_train, y_train)\nstacked_train_pred = stacked_averaged_models.predict(X_train)\nstacked_pred = np.expm1(stacked_averaged_models.predict(X_test))\nprint(rmsle(y_train, stacked_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89b95cc6aa32d245a17fbb22f463f7067f24a40f","_cell_guid":"355cfb6b-a2d7-4a10-92d8-1d4603faa600"},"cell_type":"markdown","source":"### Final Training and Prediction"},{"metadata":{"collapsed":true,"_uuid":"4aac56063f5daa6075527a701f94a5c8bdd0e4ef","_cell_guid":"497aed3d-b777-471b-9723-3a828673fe3a","trusted":false},"cell_type":"code","source":"'''#XGBoost\nmodel_xgb.fit(train, y_train)\nxgb_train_pred = model_xgb.predict(train)\nxgb_pred = np.expm1(model_xgb.predict(test))\nprint(rmsle(y_train, xgb_train_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"56cbf14cdfd71ad74822d7621c4859e6d2f90b52","_cell_guid":"6521e9c3-f598-4960-8835-902c66ed7b6b","trusted":false},"cell_type":"code","source":"'''#LightGBM\nmodel_lgb.fit(train, y_train)\nlgb_train_pred = model_lgb.predict(train)\nlgb_pred = np.expm1(model_lgb.predict(test.values))\nprint(rmsle(y_train, lgb_train_pred))\n'''","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"a40effabdc83aa93220ea9ebe27f9ea1f4112fe9","_cell_guid":"51c4dc71-14b0-4b18-8a97-94d349a370c9","trusted":false},"cell_type":"code","source":"'''RMSE on the entire Train data when averaging\n\nprint('RMSLE score on train data:')\nprint(rmsle(y_train,stacked_train_pred*0.70 +\n               xgb_train_pred*0.15 + lgb_train_pred*0.15 ))\n'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a00144458b5a728d1d63832f9ea7b9ec45e9c35d","_cell_guid":"d29ec597-2706-462b-a997-5a78f8dee2bb"},"cell_type":"markdown","source":"**Ensemble prediction:**"},{"metadata":{"collapsed":true,"_uuid":"3545f7cf5cf6adf7c93b979c9ec50c4008f8af4b","_cell_guid":"88e5de63-3da3-409b-92c0-00db7c0bacaa","trusted":false},"cell_type":"code","source":"#重くて実行不可\n#ensemble = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"d290aac93c6243d8ed3cea2c52f50898c0c4e450","_cell_guid":"76126aaf-3ada-4cf4-8b13-b7448d895716","trusted":false},"cell_type":"code","source":"'''def rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n    '''","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"5527c95ff42a32532d88ac3bbccc309c7523661c","_cell_guid":"5aac55a6-b86c-48f5-abf3-bf11b30b49b8","trusted":false},"cell_type":"code","source":"'''stacked_averaged_models.fit(d.values, y_train)\nstacked_train_pred = stacked_averaged_models.predict(X_train)\nstacked_pred = np.expm1(stacked_averaged_models.predict(X_test))\nprint(rmsle(y_train, stacked_train_pred))\n'''","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"22b6858d884511b0b8dac6853ff0a7c6a79d0e9f","_cell_guid":"442173bd-1d75-42dc-8967-7cf14dcad470","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}