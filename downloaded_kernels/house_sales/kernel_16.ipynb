{"cells":[{"metadata":{"_uuid":"30b8cb1fa107a4777ee4606c0107e5abea738814"},"cell_type":"markdown","source":"# 住宅販売価格を予測する\nHouse Sales in King County, USA   \niiyama3"},{"metadata":{"_uuid":"898714987b514ad7cefbf2f0500b9f314e507fbf"},"cell_type":"markdown","source":"---\n### 目次\n1. 　関数   \n2. 　データの読み込み   \n3. 　データの前処理   \n4. 　**Lasso Regression（回帰分析）**    \n5. 　**RandomForestRegressor（ランダムフォレスト） **\n   "},{"metadata":{"_uuid":"3b660de3036d021e19633ef7e95a46d13c642738"},"cell_type":"markdown","source":"# 1. 関数"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"2765a86a4848f247d9cae78a7c9b9e21fb9a1622"},"cell_type":"code","source":"###############################\n### マルチコの検出 VIFの計算\n###############################\ndef fc_vif(dfxxx):\n    from sklearn.linear_model import LinearRegression\n    df_vif = dfxxx.drop([\"price\"],axis=1)\n    for cname in df_vif.columns:\n        y=df_vif[cname]\n        X=df_vif.drop(cname, axis=1)\n        regr = LinearRegression(fit_intercept=True)\n        regr.fit(X, y)\n        rsquared = regr.score(X,y)\n        #print(cname,\":\" ,1/(1-np.power(rsquared,2)))\n        if rsquared == 1:\n            print(cname,X.columns[(regr.coef_> 0.5) | (regr.coef_ < -0.5)])\n        ","execution_count":1,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"63bfc101a23e9603da7be563acacae4ec31c0bf9"},"cell_type":"code","source":"###############################\n### 変数の選択 MAE:AIC\n###############################\ndef fc_var(X, y):\n    from sklearn import linear_model\n    from sklearn.metrics import mean_squared_error, mean_absolute_error\n    from sklearn.feature_selection import SelectKBest,f_regression\n    \n    N = len(X)\n    \n    for k in range(1,len(X.columns)):\n        skb = SelectKBest(f_regression,k=k).fit(X,y)\n        sup = skb.get_support()\n        X_selected = X.transpose()[sup].transpose()\n        regr = linear_model.LinearRegression()\n        model = regr.fit(X_selected,y)\n        met = mean_absolute_error(model.predict(X_selected),y)\n        aic = N*np.log((met**2).sum()/N) + 2*k\n        print('k:',k,'MAE:',met,'AIC:',aic,X.columns[k])\n        ","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"64bcf0e0d61ab54f1fb8abac5a643b924e6700ec"},"cell_type":"markdown","source":"# 2. データの読み込み"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"ec3fa02b0786fae6b43bf52a5a6a8422b89dd796"},"cell_type":"code","source":"# モジュールの読み込み\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\npd.options.display.max_rows = 10 # 常に10行だけ表示","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d43b9d35d74504728043dae16b004c6a6cdaf579"},"cell_type":"code","source":"# データの読み込み\n#df000 = pd.read_csv(\"kc_house_data.csv\") \ndf000 = pd.read_csv(\"../input/kc_house_data.csv\") \ndisplay(df000.head())","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"7859b0d99e989e251dcd58867b8b9fa8c0689016"},"cell_type":"markdown","source":"# 3. データの前処理"},{"metadata":{"trusted":false,"_uuid":"eb49c4cb2e9cd63b5542eae47cc571ff0c0637e0"},"cell_type":"code","source":"df600 = df000.drop(['date'],axis=1) #dataの削除\n#相関係数表示\ndf600.corr().style.background_gradient().format(\"{:.2f}\") # わかりやすく色付け表示","execution_count":5,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0968e75b7868426eab10a338500e5a467f664560"},"cell_type":"code","source":"# マルチコの検出 VIFの計算\nrc = fc_vif(df600)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"4101d596830930571e7ca27d68720397fa44792f"},"cell_type":"markdown","source":"#### sqft_basementを削除\n理由 sqft_basement + sqft_above = sqft_living のため強相関であり、\nまた、sqft_basementには\"0\"が含まれるため"},{"metadata":{"trusted":false,"_uuid":"2efc01fa44da0fdd1e75af9664c8709dfe49601f"},"cell_type":"code","source":"df700 = df600.drop(['sqft_basement','yr_renovated','zipcode','id'],axis=1)\n\nfor c in df700.columns: # 列の分だけ繰り返す\n    if (c != \"price\") & (c != \"date\"): # ただし、price自身と日付は除く\n        df000[[c,\"price\"]].plot(kind=\"scatter\",x=c,y=\"price\") # priceとの散布図","execution_count":7,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"232c4bad3b749fc335b4e3c47003869364c79a0a"},"cell_type":"code","source":"# マルチコの検出 VIFの計算（再度）→　\nrc = fc_vif(df700)","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"a59c08b96f37886b645b1dc35a3a7719b0a2391b"},"cell_type":"markdown","source":"マルチコは検出されなくなった"},{"metadata":{"trusted":false,"_uuid":"9e9d0873e528f0d99b123c82476e616edb759d51"},"cell_type":"code","source":"df800 = df700\nX = df800.drop(['price'],axis=1)\ny = df800['price']\n\n#V変数の選択\nrc = fc_var(X, y)","execution_count":9,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e4e5a02c3fb6bce16c534a0fcba553ac7864ae1c"},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nregr = LinearRegression(fit_intercept=True).fit(X,y)\npd.Series(regr.coef_,index=X.columns).sort_values()\\\n  .plot(kind='barh',figsize=(6,8))","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"03d56a007363d223bd017e7c03c5f897475828ca"},"cell_type":"markdown","source":"# 4. Lasso Regression（回帰分析）\n必要そうな特徴量だけを自動で取捨選択してくれる"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"079c1318e091af401e48ae6c1f1de582c68f1034"},"cell_type":"code","source":"# データをリセット\ndf800 = df700\nX = df800.drop(['price'],axis=1)\ny = df800['price']","execution_count":18,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e091a989f14600781b774cfade9ea09282f8f780"},"cell_type":"code","source":"# グリッドサーチ\nfrom sklearn.model_selection import train_test_split                # データ分割用\nfrom sklearn.model_selection import KFold                           # 交差検証用\nfrom sklearn.model_selection import GridSearchCV # グリッドサーチ\nfrom sklearn.metrics import confusion_matrix\n\n# 学習データとテストデータに分割\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n# 交差検証用に分割\nkf = KFold(n_splits=5, random_state=1234, shuffle=True)\ndf_result = pd.DataFrame()\nmodel001 = []\n\n\nfrom sklearn.linear_model import Lasso # Lasso回帰用\n# 優れたハイパーパラメータを見つけたいモデル\nmodel001 = Lasso() \n\n# 試行するハイパーパラメータ\nparms1 = [\n    {\"alpha\":np.logspace(-3,1,100)},\n]\n\ngrid_search = GridSearchCV(model001,            # モデルを渡す\n                           param_grid = parms1, # 試行してほしいパラメータを渡す\n                           cv=10,               # 汎化性能を調べる\n                          )\ngrid_search.fit(X,y) # グリッドサーチにハイパーパラメータを探す\n\nprint(grid_search.best_score_)  # 最も良かったスコア\nprint(grid_search.best_params_)  # 上記を記録したパラメータの組み合わせ\nprint(grid_search.best_estimator_.get_params())","execution_count":19,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7725f9f1f1725da4c959b2652e063ee1738cf27f"},"cell_type":"code","source":"from sklearn.linear_model import Lasso                       # Lasso回帰用\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error #MAE,MAE用\nfrom sklearn.model_selection import KFold                           # 交差検証用\nfrom sklearn.model_selection import train_test_split                # データ分割用\n\n#--------------------------------------------\n# データの整形——説明変数xの各次元を正規化\n#--------------------------------------------\nfrom sklearn import preprocessing # 正規化用\nsc = preprocessing.StandardScaler()\nsc.fit(X)\nX = sc.transform(X)\n#--------------------------------------------\n\n# 学習データとテストデータに分割\nX_train,X_test,y_train,y_test = train_test_split(np.array(X),np.array(y),test_size=0.2,random_state=42)\nkf = KFold(n_splits=5, random_state=1234, shuffle=True)\ndf_result = pd.DataFrame()\nmodels = []\n\nfor i,(train_index, val_index) in enumerate(kf.split(X_train, y_train)):\n    X_train_train, X_train_val = X_train[train_index], X_train[val_index]\n    y_train_train, y_train_val = y_train[train_index], y_train[val_index]\n\n    regr = Lasso(alpha=10.0, max_iter=1000, copy_X=True) #  Lassoを適用（ハイパーパラメーターにをセット）\n    regr.fit(X_train_train, y_train_train)\n    models.append(regr)\n    y_pred = regr.predict(X_train_val)\n    df999 = pd.DataFrame({\"y_val\":y_train_val, \"y_pred\":y_pred})\n    df_result = pd.concat([df_result, df999], axis=0)\n    \n# validation dataによる評価指標の算出\n    y_val = df_result[\"y_val\"]\n    y_pred = df_result[\"y_pred\"]\n    mse = mean_squared_error(y_val, y_pred)\n    mae = mean_absolute_error(y_val, y_pred)\n    print(\"**** Training set score( {} ):  MSE={:.3f}  RMSE={:.3f}  MAE={:.3f}  Score={:.3f} ****\".format(i,round(mse,3),round(np.sqrt(mse), 3),round(mae,3),regr.score(X_train, y_train)))\n","execution_count":20,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"952372189b177ad4fb2d6efc8b03b0ef01a2457a"},"cell_type":"code","source":"#--------------------------------------------\n# 交差検証：テスト実施\n#--------------------------------------------\nz = 1 # 訓練で一番良かったものをセット\ny_pred = models[z].predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nprint(\"**** Test     set score( {} ):  MSE={:.3f}  RMSE={:.3f}  MAE={:.3f}  Score={:.3f} ****\".format(z,round(mse,3),round(np.sqrt(mse), 3),round(mae,3),regr.score(X_test, y_test)))\nprint(\"**** Number of features used: {} ****\".format(np.sum(regr.coef_ != 0)))\n","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"76472e5ffa5d9c2529aab876ac2b85b72b9d1907"},"cell_type":"markdown","source":"# 5. RandomForest（ランダムフォレスト）\n\nパラメーター指定なし"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"0879e997cb7502971f80ad71eb16f0aaac08914f"},"cell_type":"code","source":"# データをリセット\ndf800 = df700\nX = df800.drop(['price'],axis=1)\ny = df800['price']\nbase_model = []","execution_count":22,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2289ee349b9799d98160f6292c5bc30b785fe4b7"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor # RandomForestライブラリ\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error #MAE,MAE用\nfrom sklearn.model_selection import KFold                           # 交差検証用\nfrom sklearn.model_selection import train_test_split                # データ分割用\n\n#--------------------------------------------\n# データの整形——説明変数xの各次元を正規化\n#--------------------------------------------\nfrom sklearn import preprocessing # 正規化用\nsc = preprocessing.StandardScaler()\nsc.fit(X)\nX = sc.transform(X)\n#--------------------------------------------\n\n# 学習データとテストデータに分割\nX_train,X_test,y_train,y_test = train_test_split(np.array(X),np.array(y),test_size=0.2,random_state=42)\nkf = KFold(n_splits=5, random_state=1234, shuffle=True)\ndf_result = pd.DataFrame()\nbase_model = []\n\nfor i,(train_index, val_index) in enumerate(kf.split(X_train, y_train)):\n    X_train_train, X_train_val = X_train[train_index], X_train[val_index]\n    y_train_train, y_train_val = y_train[train_index], y_train[val_index]\n\n    regr = RandomForestRegressor() \n    regr.fit(X_train_train, y_train_train)\n    base_model.append(regr)\n    y_pred = regr.predict(X_train_val)\n    df999 = pd.DataFrame({\"y_val\": y_train_val, \"y_pred\": y_pred})\n    df_result = pd.concat([df_result, df999], axis=0)\n    \n# validation dataによる評価指標の算出\n    y_val = df_result[\"y_val\"]\n    y_pred = df_result[\"y_pred\"]\n    mse = mean_squared_error(y_val, y_pred)\n    mae = mean_absolute_error(y_val, y_pred)\n    print(\"**** Training set score( {} ):  MSE={:.3f}  RMSE={:.3f}  MAE={:.3f}  Score={:.3f} ****\".format(i,round(mse,3),round(np.sqrt(mse), 3),round(mae,3),regr.score(X_train, y_train)))\n","execution_count":23,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"580975268c994c10f677d13c40609a725d1a371d"},"cell_type":"code","source":"#--------------------------------------------\n# 交差検証：テスト実施\n#--------------------------------------------\nz = 0 # 訓練で一番良かったものをセット\ny_pred = base_model[z].predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nprint(\"**** Test     set score( {} ):  MSE={:.3f}  RMSE={:.3f}  MAE={:.3f}  Score={:.3f} ****\".format(z,round(mse,3),round(np.sqrt(mse), 3),round(mae,3),regr.score(X_test, y_test)))\nprint('Parameters currently in use:')\n\nfrom pprint import pprint\npprint(regr.get_params())","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"81b549afd08d3c71db171728f0f8ef23efaf3e7b"},"cell_type":"markdown","source":"過学習気味？なのでチューニングしてみる"},{"metadata":{"_uuid":"bd00b61b1ddfb014690d372e4629ff4f9bcbca55"},"cell_type":"markdown","source":"# 5. RandomForest（ランダムフォレスト）\n\n* n_estimators =フォレスト内の樹木の数\n* max_features =ノードの分割に考慮されるフィーチャの最大数\n* max_depth =各決定木のレベルの最大数\n* min_samples_split =ノードが分割される前にノードに配置されたデータポイントの最小数\n* min_samples_leaf =リーフノードで許容されるデータポイントの最小数\n* bootstrap =データポイントをサンプリングする方法（置換の有無にかかわらず）"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"a9196594728c939fc92479d7e47701d669ff5982"},"cell_type":"code","source":"# データをリセット\ndf800 = df700\nX = df800.drop(['price'],axis=1)\ny = df800['price']\nbase_model = []","execution_count":26,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bdcdd52c717fcf6b1fa4dddf5055f7d440f44e88"},"cell_type":"code","source":"# グリッドサーチ\nfrom sklearn.model_selection import train_test_split                # データ分割用\nfrom sklearn.model_selection import KFold                           # 交差検証用\nfrom sklearn.model_selection import GridSearchCV # グリッドサーチ\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error #MAE,MAE用\nfrom sklearn.metrics import confusion_matrix\n\n\n# 学習データとテストデータに分割\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n# 交差検証用に分割\nkf = KFold(n_splits=5, random_state=1234, shuffle=True)\ndf_result = pd.DataFrame()\n\n# チューニングしたいモデル\nfrom sklearn.ensemble import RandomForestRegressor # RandomForestライブラリ\nbase_model = RandomForestRegressor() \n\n# 試行するハイパーパラメータ\nrandom_grid = {\n    'n_estimators':[10, 100, 200, 400],\n    'max_depth':[1, 9, 15],\n    'min_samples_leaf':[3, 5, 9],\n    'min_samples_split':[3, 5, 9],\n    'bootstrap':[True, False],\n    'n_jobs': [-1],\n}\n#pprint(random_grid)\nprint(\"-- GridSearch --\")\n\n# -------- パラメーターチューニング\ngrid_search = GridSearchCV(base_model,            # モデルを渡す\n                           random_grid, # 試行してほしいパラメータを渡す\n                           cv=3               # 汎化性能を調べる\n                          )\ngrid_search.fit(X,y) # グリッドサーチにハイパーパラメータを探す\n\nprint(grid_search.best_score_)  # 最も良かったスコア\nprint(grid_search.best_params_)  # 上記を記録したパラメータの組み合わせ\npprint(grid_search.best_estimator_.get_params())","execution_count":35,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e38a9b3f736978c1a00412f2f2cfe96f27577b84"},"cell_type":"code","source":"# 交差検証\nfrom sklearn.ensemble import RandomForestRegressor # RandomForestライブラリ\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error #MAE,MAE用\nfrom sklearn.model_selection import KFold                           # 交差検証用\nfrom sklearn.model_selection import train_test_split                # データ分割用\n\n# 学習データとテストデータに分割\nX_train,X_test,y_train,y_test = train_test_split(np.array(X),np.array(y),test_size=0.2,random_state=42)\nkf = KFold(n_splits=5, random_state=1234, shuffle=True)\ndf_result = pd.DataFrame()\nbase_model = []\n\nfor i,(train_index, val_index) in enumerate(kf.split(X_train, y_train)):\n    X_train_train, X_train_val = X_train[train_index], X_train[val_index]\n    y_train_train, y_train_val = y_train[train_index], y_train[val_index]\n    \n    regr = RandomForestRegressor(\n        bootstrap = True,\n        criterion = 'mse',\n        max_depth = 7,          # １５ -> \n        max_features = 'auto',\n        max_leaf_nodes = None,\n        min_impurity_decrease = 0.0,\n        min_impurity_split = None,\n        min_samples_leaf = 3,\n        min_samples_split = 5,\n        min_weight_fraction_leaf = 0.0,\n        n_estimators = 400,\n        n_jobs = -1,\n        oob_score = False,\n        random_state = None,\n        verbose = 0,\n        warm_start = False,\n    ) \n    regr.fit(X_train_train, y_train_train)\n    base_model.append(regr)\n    y_pred = regr.predict(X_train_val)\n    df999 = pd.DataFrame({\"y_val\": y_train_val, \"y_pred\": y_pred})\n    df_result = pd.concat([df_result, df999], axis=0)\n# validation dataによる評価指標の算出\n    y_val = df_result[\"y_val\"]\n    y_pred = df_result[\"y_pred\"]\n    mse = mean_squared_error(y_val, y_pred)\n    mae = mean_absolute_error(y_val, y_pred)\n    print(\"**** Training set score( {} ):  MSE={:.3f}  RMSE={:.3f}  MAE={:.3f}  Score={:.3f} ****\".format(i,round(mse,3),round(np.sqrt(mse), 3),round(mae,3),regr.score(X_train, y_train)))\n","execution_count":49,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"763c4e5523d6f68dcf914d471bfa7ba8ef8b15d4"},"cell_type":"code","source":"#--------------------------------------------\n# 交差検証：テスト実施\n#--------------------------------------------\nz = 0 # 訓練で一番良かったものをセット\ny_pred = base_model[z].predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nprint(\"**** Test     set score( {} ):  MSE={:.3f}  RMSE={:.3f}  MAE={:.3f}  Score={:.3f} ****\".format(z,round(mse,3),round(np.sqrt(mse), 3),round(mae,3),regr.score(X_test, y_test)))\nprint('Parameters currently in use:')\n\nfrom pprint import pprint\npprint(regr.get_params())","execution_count":50,"outputs":[]},{"metadata":{"_uuid":"bfdbbfd4571498fa775e79b444610610cec3e9e0"},"cell_type":"markdown","source":"RandomForestは高いスコアを出せるが、過学習にならないためのチューニングが必要なのかなぁ"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"e6707ac07701b323376526a65e6e299991c1d0d9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}